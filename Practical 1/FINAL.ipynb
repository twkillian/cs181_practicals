{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, ElasticNetCV, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rdkit import DataStructs, Chem\n",
    "from rdkit.Chem import AllChem, Descriptors, Lipinski, Fragments, rdmolops\n",
    "from rdkit.ML.Cluster import Butina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *IF FEATURE ENGINEERING IS DONE: DO NOT START HERE*\n",
    "# *SKIP TO THE START OF SECTION IV: MODEL SELECTION*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in training data\n",
    "df_train = pd.read_csv(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df_train.gap.values, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "I see some outliers around -1.5.  Having negative values makes no sense, since the gap is highest - lowest -- they must be misrecorded.  ==> Remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove negative HOMO-LUMO gaps\n",
    "df_train = df_train[df_train['gap'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot histogram of gaps without negative values\n",
    "plt.hist(df_train.gap.values, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Training Data Processing and Feature Engineering\n",
    "1. Drop all columns except smiles and gaps\n",
    "2. Add \"key\" column, partition the data, and save those partitions\n",
    "3. Remove all dataframes from memory\n",
    "4. Load each partition (1 by 1), perform feature engineering, and save each partition to a csv\n",
    "5. Reaggregate all partitions into one df, merge add binary-valued features from original training dataset, and save to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Drop all columns except smiles and gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove all columns except smiles and gaps\n",
    "df_train = df_train.drop(df_train.columns[range(1,257)], axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add \"key\" column, partition the data, and save those partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add key column\n",
    "df_train['key'] = df_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_parts = 10\n",
    "df_train_parts = np.array_split(df_train, num_parts)\n",
    "for i in xrange(len(df_train_parts)):\n",
    "    df_train_parts[i].to_csv('smiles_gaps_keys_df_train_part_'+str(i)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Remove all dataframes from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_train\n",
    "del df_train_parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load each partition (1 by 1), perform feature engineering, and save each partition to a csv\n",
    "\n",
    "(http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/). \n",
    "\n",
    "#### Number of Branches\n",
    "The idea is that the number of  [branches](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system#Branching) influences the gap between HOMO and LUMO levels.\n",
    "\n",
    "#### Note: We pull the specific compounds of intereste from [this poster.](http://digitalscholarship.unlv.edu/cgi/viewcontent.cgi?article=1036&context=focs_ug_research)\n",
    "\n",
    "#### Benzene Ring\n",
    "The last feature is determining, from the SMILES encoding whether or not there is a benzene ring in the compound. Benzene rings are held together with pi bonds which are more conjugated (which means they are closer together in energy)\n",
    "\n",
    "#### Number of Double Bonds\n",
    "\n",
    "#### Additional Features engineered using from RDKit library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(num_parts):\n",
    "    df_train_part = pd.read_csv('smiles_gaps_keys_df_train_part_'+str(i)+'.csv')\n",
    "    \n",
    "    # Apply feature engineering to train data\n",
    "    num_branches = df_train_part.smiles.apply(lambda x: x.count('('))\n",
    "    has_benzothiophene = df_train_part.smiles.apply(lambda x: min(1,x.count('s2c1ccccc1cc2')))\n",
    "    has_carbazole = df_train_part.smiles.apply(lambda x: min(1,x.count('c1ccc2c(c1)c3ccccc3[nH]2')))\n",
    "    has_fluorene = df_train_part.smiles.apply(lambda x: min(1,x.count('c1ccc-2c(c1)Cc3c2cccc3')))\n",
    "    num_double_bonds = df_train_part.smiles.apply(lambda x: x.count('='))\n",
    "    df_train_part['num_branches'] = num_branches\n",
    "    df_train_part['has_benzothiophene'] = has_benzothiophene\n",
    "    df_train_part['has_carbazole'] = has_carbazole\n",
    "    df_train_part['has_fluorene'] = has_fluorene\n",
    "    df_train_part['num_double_bonds'] = num_double_bonds\n",
    "    print \"Part {}: finished initial feat gen\".format(i)\n",
    "    # RDKit Feature Engineering\n",
    "    # Generate molecule objects\n",
    "    molecules = df_train_part.smiles.apply(lambda x: Chem.MolFromSmiles(x))\n",
    "    print \"Part {}: finished molecule generation\".format(i)\n",
    "    # Generate Features\n",
    "    df_train_part['avg_molecular_weight'] = molecules.apply(lambda x: Descriptors.MolWt(x))\n",
    "    print \"Part {}: finished first feature\".format(i)\n",
    "    df_train_part['exact_molecular_weight'] = molecules.apply(lambda x: Descriptors.ExactMolWt(x))\n",
    "    df_train_part['avg_molecular_weight_ignore_hydrogen'] = molecules.apply(lambda x: Descriptors.HeavyAtomMolWt(x))\n",
    "    df_train_part['num_valence_electrons'] = molecules.apply(lambda x: Descriptors.NumValenceElectrons(x))\n",
    "    df_train_part['num_radical_electrons'] = molecules.apply(lambda x: Descriptors.NumRadicalElectrons(x))\n",
    "    df_train_part['formal_charge'] = molecules.apply(lambda x: rdmolops.GetFormalCharge(x))\n",
    "    df_train_part['sssr'] = molecules.apply(lambda x: rdmolops.GetSSSR(x))\n",
    "    print \"Part {}: finished Descriptors and rdmolops\".format(i)\n",
    "    df_train_part['fraction_csp3'] = molecules.apply(lambda x: Lipinski.FractionCSP3(x))\n",
    "    df_train_part['num_aliphatic_carbocycles'] = molecules.apply(lambda x: Lipinski.NumAliphaticCarbocycles(x))\n",
    "    df_train_part['num_aliphatic_heterocycles'] = molecules.apply(lambda x: Lipinski.NumAliphaticHeterocycles(x))\n",
    "    df_train_part['num_aliphatic_rings'] = molecules.apply(lambda x: Lipinski.NumAliphaticRings(x))\n",
    "    df_train_part['num_aromatic_carbocycles'] = molecules.apply(lambda x: Lipinski.NumAromaticCarbocycles(x))\n",
    "    df_train_part['num_aromatic_heterocycles'] = molecules.apply(lambda x: Lipinski.NumAromaticHeterocycles(x))\n",
    "    df_train_part['num_aromatic_rings'] = molecules.apply(lambda x: Lipinski.NumAromaticRings(x))\n",
    "    df_train_part['num_saturated_carbocycles'] = molecules.apply(lambda x: Lipinski.NumSaturatedCarbocycles(x))\n",
    "    df_train_part['num_saturated_heterocycles'] = molecules.apply(lambda x: Lipinski.NumSaturatedHeterocycles(x))\n",
    "    df_train_part['num_saturated_rings'] = molecules.apply(lambda x: Lipinski.NumSaturatedRings(x))\n",
    "    df_train_part['num_nh_oh'] = molecules.apply(lambda x: Lipinski.NHOHCount(x))\n",
    "    df_train_part['num_num_rotatable_bonds'] = molecules.apply(lambda x: Lipinski.NumRotatableBonds(x))\n",
    "    df_train_part['num_heteroatoms'] = molecules.apply(lambda x: Lipinski.NumHeteroatoms(x))\n",
    "    df_train_part['num_h_acceptors'] = molecules.apply(lambda x: Lipinski.NumHAcceptors(x))\n",
    "    df_train_part['num_h_donors'] = molecules.apply(lambda x: Lipinski.NumHDonors(x))\n",
    "    df_train_part['ring_count'] = molecules.apply(lambda x: Lipinski.RingCount(x))\n",
    "    print \"Part {}: finished Lipinski\".format(i)\n",
    "    # See Parsing_methods_from_rdk_source.ipynb\n",
    "    df_train_part['fr_Al_COO'] = molecules.apply(lambda x: Fragments.fr_Al_COO(x))\n",
    "    df_train_part['fr_Al_OH'] = molecules.apply(lambda x: Fragments.fr_Al_OH(x))\n",
    "    df_train_part['fr_Al_OH_noTert'] = molecules.apply(lambda x: Fragments.fr_Al_OH_noTert(x))\n",
    "    df_train_part['fr_ArN'] = molecules.apply(lambda x: Fragments.fr_ArN(x))\n",
    "    df_train_part['fr_Ar_COO'] = molecules.apply(lambda x: Fragments.fr_Ar_COO(x))\n",
    "    df_train_part['fr_Ar_N'] = molecules.apply(lambda x: Fragments.fr_Ar_N(x))\n",
    "    df_train_part['fr_Ar_NH'] = molecules.apply(lambda x: Fragments.fr_Ar_NH(x))\n",
    "    df_train_part['fr_Ar_OH'] = molecules.apply(lambda x: Fragments.fr_Ar_OH(x))\n",
    "    df_train_part['fr_COO'] = molecules.apply(lambda x: Fragments.fr_COO(x))\n",
    "    df_train_part['fr_COO2'] = molecules.apply(lambda x: Fragments.fr_COO2(x))\n",
    "    df_train_part['fr_C_O'] = molecules.apply(lambda x: Fragments.fr_C_O(x))\n",
    "    df_train_part['fr_C_O_noCOO'] = molecules.apply(lambda x: Fragments.fr_C_O_noCOO(x))\n",
    "    df_train_part['fr_C_S'] = molecules.apply(lambda x: Fragments.fr_C_S(x))\n",
    "    df_train_part['fr_HOCCN'] = molecules.apply(lambda x: Fragments.fr_HOCCN(x))\n",
    "    df_train_part['fr_Imine'] = molecules.apply(lambda x: Fragments.fr_Imine(x))\n",
    "    df_train_part['fr_NH0'] = molecules.apply(lambda x: Fragments.fr_NH0(x))\n",
    "    df_train_part['fr_NH1'] = molecules.apply(lambda x: Fragments.fr_NH1(x))\n",
    "    df_train_part['fr_NH2'] = molecules.apply(lambda x: Fragments.fr_NH2(x))\n",
    "    df_train_part['fr_N_O'] = molecules.apply(lambda x: Fragments.fr_N_O(x))\n",
    "    df_train_part['fr_Ndealkylation1'] = molecules.apply(lambda x: Fragments.fr_Ndealkylation1(x))\n",
    "    df_train_part['fr_Ndealkylation2'] = molecules.apply(lambda x: Fragments.fr_Ndealkylation2(x))\n",
    "    df_train_part['fr_Nhpyrrole'] = molecules.apply(lambda x: Fragments.fr_Nhpyrrole(x))\n",
    "    df_train_part['fr_SH'] = molecules.apply(lambda x: Fragments.fr_SH(x))\n",
    "    df_train_part['fr_aldehyde'] = molecules.apply(lambda x: Fragments.fr_aldehyde(x))\n",
    "    df_train_part['fr_alkyl_carbamate'] = molecules.apply(lambda x: Fragments.fr_alkyl_carbamate(x))\n",
    "    df_train_part['fr_alkyl_halide'] = molecules.apply(lambda x: Fragments.fr_alkyl_halide(x))\n",
    "    df_train_part['fr_allylic_oxid'] = molecules.apply(lambda x: Fragments.fr_allylic_oxid(x))\n",
    "    df_train_part['fr_amide'] = molecules.apply(lambda x: Fragments.fr_amide(x))\n",
    "    df_train_part['fr_amidine'] = molecules.apply(lambda x: Fragments.fr_amidine(x))\n",
    "    df_train_part['fr_aniline'] = molecules.apply(lambda x: Fragments.fr_aniline(x))\n",
    "    df_train_part['fr_aryl_methyl'] = molecules.apply(lambda x: Fragments.fr_aryl_methyl(x))\n",
    "    df_train_part['fr_azide'] = molecules.apply(lambda x: Fragments.fr_azide(x))\n",
    "    df_train_part['fr_azo'] = molecules.apply(lambda x: Fragments.fr_azo(x))\n",
    "    df_train_part['fr_barbitur'] = molecules.apply(lambda x: Fragments.fr_barbitur(x))\n",
    "    df_train_part['fr_benzene'] = molecules.apply(lambda x: Fragments.fr_benzene(x))\n",
    "    df_train_part['fr_benzodiazepine'] = molecules.apply(lambda x: Fragments.fr_benzodiazepine(x))\n",
    "    df_train_part['fr_bicyclic'] = molecules.apply(lambda x: Fragments.fr_bicyclic(x))\n",
    "    df_train_part['fr_diazo'] = molecules.apply(lambda x: Fragments.fr_diazo(x))\n",
    "    df_train_part['fr_dihydropyridine'] = molecules.apply(lambda x: Fragments.fr_dihydropyridine(x))\n",
    "    df_train_part['fr_epoxide'] = molecules.apply(lambda x: Fragments.fr_epoxide(x))\n",
    "    df_train_part['fr_ester'] = molecules.apply(lambda x: Fragments.fr_ester(x))\n",
    "    df_train_part['fr_ether'] = molecules.apply(lambda x: Fragments.fr_ether(x))\n",
    "    df_train_part['fr_furan'] = molecules.apply(lambda x: Fragments.fr_furan(x))\n",
    "    df_train_part['fr_guanido'] = molecules.apply(lambda x: Fragments.fr_guanido(x))\n",
    "    df_train_part['fr_halogen'] = molecules.apply(lambda x: Fragments.fr_halogen(x))\n",
    "    df_train_part['fr_hdrzine'] = molecules.apply(lambda x: Fragments.fr_hdrzine(x))\n",
    "    df_train_part['fr_hdrzone'] = molecules.apply(lambda x: Fragments.fr_hdrzone(x))\n",
    "    df_train_part['fr_imidazole'] = molecules.apply(lambda x: Fragments.fr_imidazole(x))\n",
    "    df_train_part['fr_imide'] = molecules.apply(lambda x: Fragments.fr_imide(x))\n",
    "    df_train_part['fr_isocyan'] = molecules.apply(lambda x: Fragments.fr_isocyan(x))\n",
    "    df_train_part['fr_isothiocyan'] = molecules.apply(lambda x: Fragments.fr_isothiocyan(x))\n",
    "    df_train_part['fr_ketone'] = molecules.apply(lambda x: Fragments.fr_ketone(x))\n",
    "    df_train_part['fr_lactam'] = molecules.apply(lambda x: Fragments.fr_lactam(x))\n",
    "    df_train_part['fr_lactone'] = molecules.apply(lambda x: Fragments.fr_lactone(x))\n",
    "    df_train_part['fr_methoxy'] = molecules.apply(lambda x: Fragments.fr_methoxy(x))\n",
    "    df_train_part['fr_morpholine'] = molecules.apply(lambda x: Fragments.fr_morpholine(x))\n",
    "    df_train_part['fr_nitrile'] = molecules.apply(lambda x: Fragments.fr_nitrile(x))\n",
    "    df_train_part['fr_nitro'] = molecules.apply(lambda x: Fragments.fr_nitro(x))\n",
    "    df_train_part['fr_nitro_arom'] = molecules.apply(lambda x: Fragments.fr_nitro_arom(x))\n",
    "    df_train_part['fr_nitro_arom_nonortho'] = molecules.apply(lambda x: Fragments.fr_nitro_arom_nonortho(x))\n",
    "    df_train_part['fr_nitroso'] = molecules.apply(lambda x: Fragments.fr_nitroso(x))\n",
    "    df_train_part['fr_oxazole'] = molecules.apply(lambda x: Fragments.fr_oxazole(x))\n",
    "    df_train_part['fr_oxime'] = molecules.apply(lambda x: Fragments.fr_oxime(x))\n",
    "    df_train_part['fr_para_hydroxylation'] = molecules.apply(lambda x: Fragments.fr_para_hydroxylation(x))\n",
    "    df_train_part['fr_phenol'] = molecules.apply(lambda x: Fragments.fr_phenol(x))\n",
    "    df_train_part['fr_phenol_noOrthoHbond'] = molecules.apply(lambda x: Fragments.fr_phenol_noOrthoHbond(x))\n",
    "    df_train_part['fr_phos_acid'] = molecules.apply(lambda x: Fragments.fr_phos_acid(x))\n",
    "    df_train_part['fr_phos_ester'] = molecules.apply(lambda x: Fragments.fr_phos_ester(x))\n",
    "    df_train_part['fr_piperdine'] = molecules.apply(lambda x: Fragments.fr_piperdine(x))\n",
    "    df_train_part['fr_piperzine'] = molecules.apply(lambda x: Fragments.fr_piperzine(x))\n",
    "    df_train_part['fr_priamide'] = molecules.apply(lambda x: Fragments.fr_priamide(x))\n",
    "    df_train_part['fr_prisulfonamd'] = molecules.apply(lambda x: Fragments.fr_prisulfonamd(x))\n",
    "    df_train_part['fr_pyridine'] = molecules.apply(lambda x: Fragments.fr_pyridine(x))\n",
    "    df_train_part['fr_quatN'] = molecules.apply(lambda x: Fragments.fr_quatN(x))\n",
    "    df_train_part['fr_sulfide'] = molecules.apply(lambda x: Fragments.fr_sulfide(x))\n",
    "    df_train_part['fr_sulfonamd'] = molecules.apply(lambda x: Fragments.fr_sulfonamd(x))\n",
    "    df_train_part['fr_sulfone'] = molecules.apply(lambda x: Fragments.fr_sulfone(x))\n",
    "    df_train_part['fr_term_acetylene'] = molecules.apply(lambda x: Fragments.fr_term_acetylene(x))\n",
    "    df_train_part['fr_tetrazole'] = molecules.apply(lambda x: Fragments.fr_tetrazole(x))\n",
    "    df_train_part['fr_thiazole'] = molecules.apply(lambda x: Fragments.fr_thiazole(x))\n",
    "    df_train_part['fr_thiocyan'] = molecules.apply(lambda x: Fragments.fr_thiocyan(x))\n",
    "    df_train_part['fr_thiophene'] = molecules.apply(lambda x: Fragments.fr_thiophene(x))\n",
    "    df_train_part['fr_unbrch_alkane'] = molecules.apply(lambda x: Fragments.fr_unbrch_alkane(x))\n",
    "    df_train_part['fr_urea'] = molecules.apply(lambda x: Fragments.fr_urea(x))\n",
    "    df_train_part['fr_ketone_Topliss'] = molecules.apply(lambda x: Fragments.fr_ketone_Topliss(x))\n",
    "    \n",
    "    print \"Part {}: finished Fragments\".format(i)\n",
    "    df_train_part.to_csv('rdk_feat_eng_df_train_part_'+str(i)+'.csv', index=False)\n",
    "    del df_train_part\n",
    "    del molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Reaggregate all partitions into one df, merge add binary-valued features from original training dataset, and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in each feature engineered partition\n",
    "df_train_parts = [pd.read_csv('rdk_feat_eng_df_train_part_'+str(i)+'.csv') for i in xrange(num_parts)]\n",
    "# concatenate them into one df\n",
    "df_train = pd.concat(df_train_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in old training\n",
    "# Note: df_train_old has same as before partitioning\n",
    "df_train_old = pd.read_csv(\"train.csv\")\n",
    "# Add key\n",
    "df_train_old['key'] = df_train_old.index\n",
    "# merge dataframes on 'key'\n",
    "df_train = df_train.merge(df_train_old, on=[\"key\"])\n",
    "# Fix columns\n",
    "df_train = df_train.drop(['gap_x'],axis=1)\n",
    "df_train = df_train.drop(['key'],axis=1)\n",
    "df_train = df_train.rename(columns = {'gap_y':'gap'})\n",
    "df_train = df_train.drop(['smiles_x'],axis=1)\n",
    "df_train = df_train.rename(columns = {'smiles_y':'smiles'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save df_train\n",
    "df_train.to_csv('FINAL_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove df_train for now\n",
    "del df_train_parts\n",
    "del df_train_old\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Test Data Processing and Feature Engineering\n",
    "1. Drop all columns except smiles and ids\n",
    "2. Partition the data and save those partitions\n",
    "3. Remove all dataframes from memory\n",
    "4. Load each partition (1 by 1), perform feature engineering, and save each partition to a csv\n",
    "5. Reaggregate all partitions into one df, merge add binary-valued features from original test dataset, and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in test data\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. Drop all columns except smiles and ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = df_test.drop(df_test.columns[range(2,258)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Partition the data and save those partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_parts = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test_parts = np.array_split(df_test, num_parts)\n",
    "for i in xrange(num_parts):\n",
    "    df_test_parts[i].to_csv('smiles_and_ids_df_test_part_'+str(i)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Remove all dataframes from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_test\n",
    "del df_test_parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load each partition (1 by 1), perform feature engineering, and save each partition to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(num_parts):\n",
    "    df_test_part = pd.read_csv('smiles_and_ids_df_test_part_'+str(i)+'.csv')\n",
    "  \n",
    "\n",
    "    # Apply feature engineering to train data\n",
    "    num_branches = df_test_part.smiles.apply(lambda x: x.count('('))\n",
    "    has_benzothiophene = df_test_part.smiles.apply(lambda x: min(1,x.count('s2c1ccccc1cc2')))\n",
    "    has_carbazole = df_test_part.smiles.apply(lambda x: min(1,x.count('c1ccc2c(c1)c3ccccc3[nH]2')))\n",
    "    has_fluorene = df_test_part.smiles.apply(lambda x: min(1,x.count('c1ccc-2c(c1)Cc3c2cccc3')))\n",
    "    num_double_bonds = df_test_part.smiles.apply(lambda x: x.count('='))\n",
    "    df_test_part['num_branches'] = num_branches\n",
    "    df_test_part['has_benzothiophene'] = has_benzothiophene\n",
    "    df_test_part['has_carbazole'] = has_carbazole\n",
    "    df_test_part['has_fluorene'] = has_fluorene\n",
    "    df_test_part['num_double_bonds'] = num_double_bonds\n",
    "    print \"Part {}: finished initial feat gen\".format(i)\n",
    "    # RDKit Feature Engineering\n",
    "    # Generate molecule objects\n",
    "    molecules = df_test_part.smiles.apply(lambda x: Chem.MolFromSmiles(x))\n",
    "    print \"Part {}: finished molecule generation\".format(i)\n",
    "    # Generate Features\n",
    "    df_test_part['avg_molecular_weight'] = molecules.apply(lambda x: Descriptors.MolWt(x))\n",
    "    print \"Part {}: finished first feature\".format(i)\n",
    "    df_test_part['exact_molecular_weight'] = molecules.apply(lambda x: Descriptors.ExactMolWt(x))\n",
    "    df_test_part['avg_molecular_weight_ignore_hydrogen'] = molecules.apply(lambda x: Descriptors.HeavyAtomMolWt(x))\n",
    "    df_test_part['num_valence_electrons'] = molecules.apply(lambda x: Descriptors.NumValenceElectrons(x))\n",
    "    df_test_part['num_radical_electrons'] = molecules.apply(lambda x: Descriptors.NumRadicalElectrons(x))\n",
    "    df_test_part['formal_charge'] = molecules.apply(lambda x: rdmolops.GetFormalCharge(x))\n",
    "    df_test_part['sssr'] = molecules.apply(lambda x: rdmolops.GetSSSR(x))\n",
    "    print \"Part {}: finished Descriptors and rdmolops\".format(i)\n",
    "    df_test_part['fraction_csp3'] = molecules.apply(lambda x: Lipinski.FractionCSP3(x))\n",
    "    df_test_part['num_aliphatic_carbocycles'] = molecules.apply(lambda x: Lipinski.NumAliphaticCarbocycles(x))\n",
    "    df_test_part['num_aliphatic_heterocycles'] = molecules.apply(lambda x: Lipinski.NumAliphaticHeterocycles(x))\n",
    "    df_test_part['num_aliphatic_rings'] = molecules.apply(lambda x: Lipinski.NumAliphaticRings(x))\n",
    "    df_test_part['num_aromatic_carbocycles'] = molecules.apply(lambda x: Lipinski.NumAromaticCarbocycles(x))\n",
    "    df_test_part['num_aromatic_heterocycles'] = molecules.apply(lambda x: Lipinski.NumAromaticHeterocycles(x))\n",
    "    df_test_part['num_aromatic_rings'] = molecules.apply(lambda x: Lipinski.NumAromaticRings(x))\n",
    "    df_test_part['num_saturated_carbocycles'] = molecules.apply(lambda x: Lipinski.NumSaturatedCarbocycles(x))\n",
    "    df_test_part['num_saturated_heterocycles'] = molecules.apply(lambda x: Lipinski.NumSaturatedHeterocycles(x))\n",
    "    df_test_part['num_saturated_rings'] = molecules.apply(lambda x: Lipinski.NumSaturatedRings(x))\n",
    "    df_test_part['num_nh_oh'] = molecules.apply(lambda x: Lipinski.NHOHCount(x))\n",
    "    df_test_part['num_num_rotatable_bonds'] = molecules.apply(lambda x: Lipinski.NumRotatableBonds(x))\n",
    "    df_test_part['num_heteroatoms'] = molecules.apply(lambda x: Lipinski.NumHeteroatoms(x))\n",
    "    df_test_part['num_h_acceptors'] = molecules.apply(lambda x: Lipinski.NumHAcceptors(x))\n",
    "    df_test_part['num_h_donors'] = molecules.apply(lambda x: Lipinski.NumHDonors(x))\n",
    "    df_test_part['ring_count'] = molecules.apply(lambda x: Lipinski.RingCount(x))\n",
    "    print \"Part {}: finished Lipinski\".format(i)\n",
    "    # See Parsing_methods_from_rdk_source.ipynb\n",
    "    df_test_part['fr_Al_COO'] = molecules.apply(lambda x: Fragments.fr_Al_COO(x))\n",
    "    df_test_part['fr_Al_OH'] = molecules.apply(lambda x: Fragments.fr_Al_OH(x))\n",
    "    df_test_part['fr_Al_OH_noTert'] = molecules.apply(lambda x: Fragments.fr_Al_OH_noTert(x))\n",
    "    df_test_part['fr_ArN'] = molecules.apply(lambda x: Fragments.fr_ArN(x))\n",
    "    df_test_part['fr_Ar_COO'] = molecules.apply(lambda x: Fragments.fr_Ar_COO(x))\n",
    "    df_test_part['fr_Ar_N'] = molecules.apply(lambda x: Fragments.fr_Ar_N(x))\n",
    "    df_test_part['fr_Ar_NH'] = molecules.apply(lambda x: Fragments.fr_Ar_NH(x))\n",
    "    df_test_part['fr_Ar_OH'] = molecules.apply(lambda x: Fragments.fr_Ar_OH(x))\n",
    "    df_test_part['fr_COO'] = molecules.apply(lambda x: Fragments.fr_COO(x))\n",
    "    df_test_part['fr_COO2'] = molecules.apply(lambda x: Fragments.fr_COO2(x))\n",
    "    df_test_part['fr_C_O'] = molecules.apply(lambda x: Fragments.fr_C_O(x))\n",
    "    df_test_part['fr_C_O_noCOO'] = molecules.apply(lambda x: Fragments.fr_C_O_noCOO(x))\n",
    "    df_test_part['fr_C_S'] = molecules.apply(lambda x: Fragments.fr_C_S(x))\n",
    "    df_test_part['fr_HOCCN'] = molecules.apply(lambda x: Fragments.fr_HOCCN(x))\n",
    "    df_test_part['fr_Imine'] = molecules.apply(lambda x: Fragments.fr_Imine(x))\n",
    "    df_test_part['fr_NH0'] = molecules.apply(lambda x: Fragments.fr_NH0(x))\n",
    "    df_test_part['fr_NH1'] = molecules.apply(lambda x: Fragments.fr_NH1(x))\n",
    "    df_test_part['fr_NH2'] = molecules.apply(lambda x: Fragments.fr_NH2(x))\n",
    "    df_test_part['fr_N_O'] = molecules.apply(lambda x: Fragments.fr_N_O(x))\n",
    "    df_test_part['fr_Ndealkylation1'] = molecules.apply(lambda x: Fragments.fr_Ndealkylation1(x))\n",
    "    df_test_part['fr_Ndealkylation2'] = molecules.apply(lambda x: Fragments.fr_Ndealkylation2(x))\n",
    "    df_test_part['fr_Nhpyrrole'] = molecules.apply(lambda x: Fragments.fr_Nhpyrrole(x))\n",
    "    df_test_part['fr_SH'] = molecules.apply(lambda x: Fragments.fr_SH(x))\n",
    "    df_test_part['fr_aldehyde'] = molecules.apply(lambda x: Fragments.fr_aldehyde(x))\n",
    "    df_test_part['fr_alkyl_carbamate'] = molecules.apply(lambda x: Fragments.fr_alkyl_carbamate(x))\n",
    "    df_test_part['fr_alkyl_halide'] = molecules.apply(lambda x: Fragments.fr_alkyl_halide(x))\n",
    "    df_test_part['fr_allylic_oxid'] = molecules.apply(lambda x: Fragments.fr_allylic_oxid(x))\n",
    "    df_test_part['fr_amide'] = molecules.apply(lambda x: Fragments.fr_amide(x))\n",
    "    df_test_part['fr_amidine'] = molecules.apply(lambda x: Fragments.fr_amidine(x))\n",
    "    df_test_part['fr_aniline'] = molecules.apply(lambda x: Fragments.fr_aniline(x))\n",
    "    df_test_part['fr_aryl_methyl'] = molecules.apply(lambda x: Fragments.fr_aryl_methyl(x))\n",
    "    df_test_part['fr_azide'] = molecules.apply(lambda x: Fragments.fr_azide(x))\n",
    "    df_test_part['fr_azo'] = molecules.apply(lambda x: Fragments.fr_azo(x))\n",
    "    df_test_part['fr_barbitur'] = molecules.apply(lambda x: Fragments.fr_barbitur(x))\n",
    "    df_test_part['fr_benzene'] = molecules.apply(lambda x: Fragments.fr_benzene(x))\n",
    "    df_test_part['fr_benzodiazepine'] = molecules.apply(lambda x: Fragments.fr_benzodiazepine(x))\n",
    "    df_test_part['fr_bicyclic'] = molecules.apply(lambda x: Fragments.fr_bicyclic(x))\n",
    "    df_test_part['fr_diazo'] = molecules.apply(lambda x: Fragments.fr_diazo(x))\n",
    "    df_test_part['fr_dihydropyridine'] = molecules.apply(lambda x: Fragments.fr_dihydropyridine(x))\n",
    "    df_test_part['fr_epoxide'] = molecules.apply(lambda x: Fragments.fr_epoxide(x))\n",
    "    df_test_part['fr_ester'] = molecules.apply(lambda x: Fragments.fr_ester(x))\n",
    "    df_test_part['fr_ether'] = molecules.apply(lambda x: Fragments.fr_ether(x))\n",
    "    df_test_part['fr_furan'] = molecules.apply(lambda x: Fragments.fr_furan(x))\n",
    "    df_test_part['fr_guanido'] = molecules.apply(lambda x: Fragments.fr_guanido(x))\n",
    "    df_test_part['fr_halogen'] = molecules.apply(lambda x: Fragments.fr_halogen(x))\n",
    "    df_test_part['fr_hdrzine'] = molecules.apply(lambda x: Fragments.fr_hdrzine(x))\n",
    "    df_test_part['fr_hdrzone'] = molecules.apply(lambda x: Fragments.fr_hdrzone(x))\n",
    "    df_test_part['fr_imidazole'] = molecules.apply(lambda x: Fragments.fr_imidazole(x))\n",
    "    df_test_part['fr_imide'] = molecules.apply(lambda x: Fragments.fr_imide(x))\n",
    "    df_test_part['fr_isocyan'] = molecules.apply(lambda x: Fragments.fr_isocyan(x))\n",
    "    df_test_part['fr_isothiocyan'] = molecules.apply(lambda x: Fragments.fr_isothiocyan(x))\n",
    "    df_test_part['fr_ketone'] = molecules.apply(lambda x: Fragments.fr_ketone(x))\n",
    "    df_test_part['fr_lactam'] = molecules.apply(lambda x: Fragments.fr_lactam(x))\n",
    "    df_test_part['fr_lactone'] = molecules.apply(lambda x: Fragments.fr_lactone(x))\n",
    "    df_test_part['fr_methoxy'] = molecules.apply(lambda x: Fragments.fr_methoxy(x))\n",
    "    df_test_part['fr_morpholine'] = molecules.apply(lambda x: Fragments.fr_morpholine(x))\n",
    "    df_test_part['fr_nitrile'] = molecules.apply(lambda x: Fragments.fr_nitrile(x))\n",
    "    df_test_part['fr_nitro'] = molecules.apply(lambda x: Fragments.fr_nitro(x))\n",
    "    df_test_part['fr_nitro_arom'] = molecules.apply(lambda x: Fragments.fr_nitro_arom(x))\n",
    "    df_test_part['fr_nitro_arom_nonortho'] = molecules.apply(lambda x: Fragments.fr_nitro_arom_nonortho(x))\n",
    "    df_test_part['fr_nitroso'] = molecules.apply(lambda x: Fragments.fr_nitroso(x))\n",
    "    df_test_part['fr_oxazole'] = molecules.apply(lambda x: Fragments.fr_oxazole(x))\n",
    "    df_test_part['fr_oxime'] = molecules.apply(lambda x: Fragments.fr_oxime(x))\n",
    "    df_test_part['fr_para_hydroxylation'] = molecules.apply(lambda x: Fragments.fr_para_hydroxylation(x))\n",
    "    df_test_part['fr_phenol'] = molecules.apply(lambda x: Fragments.fr_phenol(x))\n",
    "    df_test_part['fr_phenol_noOrthoHbond'] = molecules.apply(lambda x: Fragments.fr_phenol_noOrthoHbond(x))\n",
    "    df_test_part['fr_phos_acid'] = molecules.apply(lambda x: Fragments.fr_phos_acid(x))\n",
    "    df_test_part['fr_phos_ester'] = molecules.apply(lambda x: Fragments.fr_phos_ester(x))\n",
    "    df_test_part['fr_piperdine'] = molecules.apply(lambda x: Fragments.fr_piperdine(x))\n",
    "    df_test_part['fr_piperzine'] = molecules.apply(lambda x: Fragments.fr_piperzine(x))\n",
    "    df_test_part['fr_priamide'] = molecules.apply(lambda x: Fragments.fr_priamide(x))\n",
    "    df_test_part['fr_prisulfonamd'] = molecules.apply(lambda x: Fragments.fr_prisulfonamd(x))\n",
    "    df_test_part['fr_pyridine'] = molecules.apply(lambda x: Fragments.fr_pyridine(x))\n",
    "    df_test_part['fr_quatN'] = molecules.apply(lambda x: Fragments.fr_quatN(x))\n",
    "    df_test_part['fr_sulfide'] = molecules.apply(lambda x: Fragments.fr_sulfide(x))\n",
    "    df_test_part['fr_sulfonamd'] = molecules.apply(lambda x: Fragments.fr_sulfonamd(x))\n",
    "    df_test_part['fr_sulfone'] = molecules.apply(lambda x: Fragments.fr_sulfone(x))\n",
    "    df_test_part['fr_term_acetylene'] = molecules.apply(lambda x: Fragments.fr_term_acetylene(x))\n",
    "    df_test_part['fr_tetrazole'] = molecules.apply(lambda x: Fragments.fr_tetrazole(x))\n",
    "    df_test_part['fr_thiazole'] = molecules.apply(lambda x: Fragments.fr_thiazole(x))\n",
    "    df_test_part['fr_thiocyan'] = molecules.apply(lambda x: Fragments.fr_thiocyan(x))\n",
    "    df_test_part['fr_thiophene'] = molecules.apply(lambda x: Fragments.fr_thiophene(x))\n",
    "    df_test_part['fr_unbrch_alkane'] = molecules.apply(lambda x: Fragments.fr_unbrch_alkane(x))\n",
    "    df_test_part['fr_urea'] = molecules.apply(lambda x: Fragments.fr_urea(x))\n",
    "    df_test_part['fr_ketone_Topliss'] = molecules.apply(lambda x: Fragments.fr_ketone_Topliss(x))\n",
    "    \n",
    "    print \"Part {}: finished Fragments\".format(i)\n",
    "    df_test_part.to_csv('rdk_feat_eng_df_test_part_'+str(i)+'.csv', index=False)\n",
    "    del df_test_part\n",
    "    del molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Reaggregate all partitions into one df, merge add binary-valued features from original test dataset, and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in each feat eng part\n",
    "df_test_parts = [pd.read_csv('rdk_feat_eng_df_test_part_'+str(i)+'.csv') for i in xrange(num_parts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine into one df\n",
    "df_test = pd.concat(df_test_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in old test data and merge with new features\n",
    "df_test_old = pd.read_csv(\"test.csv\")\n",
    "df_test = df_test.merge(df_test_old, on=[\"Id\"])\n",
    "# Fix columns\n",
    "df_test = df_test.drop(['smiles_x'],axis=1)\n",
    "df_test = df_test.rename(columns = {'smiles_y':'smiles'})\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "df_test.to_csv('FINAL_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete old dfs\n",
    "del df_test_old\n",
    "del df_test_parts\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *IF FEATURE ENGINEERING IS DONE: START HERE*\n",
    "# IV. Model Selection \n",
    "1. Read training data, store output values, and remove output values from df_train\n",
    "2. Split training data into training set and validation set\n",
    "3. Model Selection -  Test various models\n",
    "    1. Linear Regression\n",
    "    2. Transform data using PCA\n",
    "    3. Random Forest (extra trees) using PCA\n",
    "    4. ... (TAYLOR AND ANDREW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read training data, store output values, and remove output values from df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('FINAL_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_branches</th>\n",
       "      <th>has_benzothiophene</th>\n",
       "      <th>has_carbazole</th>\n",
       "      <th>has_fluorene</th>\n",
       "      <th>num_double_bonds</th>\n",
       "      <th>avg_molecular_weight</th>\n",
       "      <th>exact_molecular_weight</th>\n",
       "      <th>avg_molecular_weight_ignore_hydrogen</th>\n",
       "      <th>num_valence_electrons</th>\n",
       "      <th>num_radical_electrons</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>470.462</td>\n",
       "      <td>470.907296</td>\n",
       "      <td>461.390</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>352.545</td>\n",
       "      <td>352.085202</td>\n",
       "      <td>336.417</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>399.576</td>\n",
       "      <td>399.032016</td>\n",
       "      <td>386.472</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>379.567</td>\n",
       "      <td>379.084867</td>\n",
       "      <td>362.431</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>396.391</td>\n",
       "      <td>396.042944</td>\n",
       "      <td>388.327</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_branches  has_benzothiophene  has_carbazole  has_fluorene  \\\n",
       "0             3                   0              0             0   \n",
       "1             1                   0              0             0   \n",
       "2             2                   0              0             0   \n",
       "3             1                   0              0             0   \n",
       "4             1                   0              0             0   \n",
       "\n",
       "   num_double_bonds  avg_molecular_weight  exact_molecular_weight  \\\n",
       "0                 0               470.462              470.907296   \n",
       "1                 5               352.545              352.085202   \n",
       "2                 1               399.576              399.032016   \n",
       "3                 4               379.567              379.084867   \n",
       "4                 0               396.391              396.042944   \n",
       "\n",
       "   avg_molecular_weight_ignore_hydrogen  num_valence_electrons  \\\n",
       "0                               461.390                    130   \n",
       "1                               336.417                    118   \n",
       "2                               386.472                    128   \n",
       "3                               362.431                    128   \n",
       "4                               388.327                    136   \n",
       "\n",
       "   num_radical_electrons  ...   feat_248  feat_249  feat_250  feat_251  \\\n",
       "0                      0  ...          1         0         0         0   \n",
       "1                      0  ...          1         0         0         1   \n",
       "2                      0  ...          1         0         0         0   \n",
       "3                      0  ...          1         0         0         0   \n",
       "4                      0  ...          1         0         0         0   \n",
       "\n",
       "   feat_252  feat_253  feat_254  feat_255  feat_256   gap  \n",
       "0         0         0         0         0         0  1.19  \n",
       "1         0         0         0         0         0  1.60  \n",
       "2         1         0         0         0         0  1.49  \n",
       "3         1         0         0         0         0  1.36  \n",
       "4         0         0         0         0         0  1.98  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (999997, 369)\n",
      "Train gap: (999997,)\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'smiles' column \n",
    "smiles = df_train.smiles.values\n",
    "df_train = df_train.drop(['smiles'], axis=1)\n",
    "\n",
    "# Store gap values\n",
    "Y_train = df_train.gap.values\n",
    "\n",
    "# Delete 'gap' column\n",
    "df_train = df_train.drop(['gap'], axis=1)\n",
    "X_train = df_train.values\n",
    "print \"Train features:\", X_train.shape\n",
    "print \"Train gap:\", Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=128, n_jobs=2, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train rf regressor\n",
    "rf_est = RandomForestRegressor(n_estimators=128,n_jobs=2, max_features='sqrt')\n",
    "rf_est.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fr_bicyclic', 0.066837312084785411),\n",
       " ('num_heteroatoms', 0.06621279132514378),\n",
       " ('feat_025', 0.057977357415829621),\n",
       " ('num_valence_electrons', 0.052716855768966224),\n",
       " ('feat_102', 0.038866604365385138),\n",
       " ('exact_molecular_weight', 0.038202059146884862),\n",
       " ('avg_molecular_weight', 0.038101911284794905),\n",
       " ('feat_119', 0.03696882049255118),\n",
       " ('num_branches', 0.036261569684482159),\n",
       " ('avg_molecular_weight_ignore_hydrogen', 0.034743792157084168),\n",
       " ('num_num_rotatable_bonds', 0.034155054188435945),\n",
       " ('num_h_acceptors', 0.032015032435348818),\n",
       " ('fr_NH0', 0.031493181331001853),\n",
       " ('feat_218', 0.029912043569035811),\n",
       " ('num_double_bonds', 0.026077931847574641),\n",
       " ('sssr', 0.025781859746211867),\n",
       " ('num_aliphatic_rings', 0.025159472420247332),\n",
       " ('fr_Ar_N', 0.024987301878706864),\n",
       " ('ring_count', 0.023287298561908011),\n",
       " ('fr_pyridine', 0.021056239368878817),\n",
       " ('num_aromatic_heterocycles', 0.019672691905820893),\n",
       " ('num_aliphatic_heterocycles', 0.018903139748309455),\n",
       " ('feat_251', 0.016177555788293475),\n",
       " ('fr_allylic_oxid', 0.01305270092864695),\n",
       " ('num_aromatic_carbocycles', 0.013030689395398656),\n",
       " ('fr_benzene', 0.012714489129083231),\n",
       " ('num_aromatic_rings', 0.012580622268579821),\n",
       " ('feat_001', 0.012162737083744662),\n",
       " ('feat_068', 0.011676410155531523),\n",
       " ('feat_072', 0.010093556915678406),\n",
       " ('feat_187', 0.010007758942152048),\n",
       " ('fraction_csp3', 0.0099099996150127014),\n",
       " ('fr_thiophene', 0.0090161241326725764),\n",
       " ('num_aliphatic_carbocycles', 0.0086748233817117194),\n",
       " ('feat_090', 0.0074411032407735965),\n",
       " ('feat_173', 0.0059947526450705923),\n",
       " ('feat_069', 0.0055558677142022207),\n",
       " ('feat_037', 0.0054705519216691314),\n",
       " ('feat_123', 0.0051977508949823167),\n",
       " ('feat_225', 0.004813212255529848),\n",
       " ('feat_126', 0.0044203947266871916),\n",
       " ('fr_furan', 0.0038487279076424661),\n",
       " ('feat_087', 0.0038335066460236356),\n",
       " ('feat_208', 0.0037705627588458944),\n",
       " ('fr_thiazole', 0.0036637610763147633),\n",
       " ('feat_248', 0.0026720910110243517),\n",
       " ('num_h_donors', 0.002558277099828568),\n",
       " ('num_nh_oh', 0.0025555987816085592),\n",
       " ('fr_Ar_NH', 0.0024898473346649441),\n",
       " ('fr_Nhpyrrole', 0.0024479920518344642),\n",
       " ('fr_NH1', 0.002270632971402078),\n",
       " ('feat_176', 0.0020081033999345306),\n",
       " ('feat_243', 0.0018353920941277229),\n",
       " ('feat_006', 0.0018288968862694528),\n",
       " ('feat_252', 0.0017903631070049855),\n",
       " ('feat_196', 0.0016172147158707573),\n",
       " ('fr_para_hydroxylation', 0.0016131774467442121),\n",
       " ('feat_132', 0.00046977229869955926),\n",
       " ('feat_226', 0.0004268614797339745),\n",
       " ('feat_007', 0.00042308805858146104),\n",
       " ('feat_044', 0.00028949346755193666),\n",
       " ('fr_aryl_methyl', 8.262487468461414e-05),\n",
       " ('feat_199', 6.822839796771084e-05),\n",
       " ('feat_200', 5.3057965257337429e-05),\n",
       " ('feat_005', 1.3063055735808553e-06),\n",
       " ('has_benzothiophene', 0.0),\n",
       " ('has_carbazole', 0.0),\n",
       " ('has_fluorene', 0.0),\n",
       " ('num_radical_electrons', 0.0),\n",
       " ('formal_charge', 0.0),\n",
       " ('num_saturated_carbocycles', 0.0),\n",
       " ('num_saturated_heterocycles', 0.0),\n",
       " ('num_saturated_rings', 0.0),\n",
       " ('fr_Al_COO', 0.0),\n",
       " ('fr_Al_OH', 0.0),\n",
       " ('fr_Al_OH_noTert', 0.0),\n",
       " ('fr_ArN', 0.0),\n",
       " ('fr_Ar_COO', 0.0),\n",
       " ('fr_Ar_OH', 0.0),\n",
       " ('fr_COO', 0.0),\n",
       " ('fr_COO2', 0.0),\n",
       " ('fr_C_O', 0.0),\n",
       " ('fr_C_O_noCOO', 0.0),\n",
       " ('fr_C_S', 0.0),\n",
       " ('fr_HOCCN', 0.0),\n",
       " ('fr_Imine', 0.0),\n",
       " ('fr_NH2', 0.0),\n",
       " ('fr_N_O', 0.0),\n",
       " ('fr_Ndealkylation1', 0.0),\n",
       " ('fr_Ndealkylation2', 0.0),\n",
       " ('fr_SH', 0.0),\n",
       " ('fr_aldehyde', 0.0),\n",
       " ('fr_alkyl_carbamate', 0.0),\n",
       " ('fr_alkyl_halide', 0.0),\n",
       " ('fr_amide', 0.0),\n",
       " ('fr_amidine', 0.0),\n",
       " ('fr_aniline', 0.0),\n",
       " ('fr_azide', 0.0),\n",
       " ('fr_azo', 0.0),\n",
       " ('fr_barbitur', 0.0),\n",
       " ('fr_benzodiazepine', 0.0),\n",
       " ('fr_diazo', 0.0),\n",
       " ('fr_dihydropyridine', 0.0),\n",
       " ('fr_epoxide', 0.0),\n",
       " ('fr_ester', 0.0),\n",
       " ('fr_ether', 0.0),\n",
       " ('fr_guanido', 0.0),\n",
       " ('fr_halogen', 0.0),\n",
       " ('fr_hdrzine', 0.0),\n",
       " ('fr_hdrzone', 0.0),\n",
       " ('fr_imidazole', 0.0),\n",
       " ('fr_imide', 0.0),\n",
       " ('fr_isocyan', 0.0),\n",
       " ('fr_isothiocyan', 0.0),\n",
       " ('fr_ketone', 0.0),\n",
       " ('fr_lactam', 0.0),\n",
       " ('fr_lactone', 0.0),\n",
       " ('fr_methoxy', 0.0),\n",
       " ('fr_morpholine', 0.0),\n",
       " ('fr_nitrile', 0.0),\n",
       " ('fr_nitro', 0.0),\n",
       " ('fr_nitro_arom', 0.0),\n",
       " ('fr_nitro_arom_nonortho', 0.0),\n",
       " ('fr_nitroso', 0.0),\n",
       " ('fr_oxazole', 0.0),\n",
       " ('fr_oxime', 0.0),\n",
       " ('fr_phenol', 0.0),\n",
       " ('fr_phenol_noOrthoHbond', 0.0),\n",
       " ('fr_phos_acid', 0.0),\n",
       " ('fr_phos_ester', 0.0),\n",
       " ('fr_piperdine', 0.0),\n",
       " ('fr_piperzine', 0.0),\n",
       " ('fr_priamide', 0.0),\n",
       " ('fr_prisulfonamd', 0.0),\n",
       " ('fr_quatN', 0.0),\n",
       " ('fr_sulfide', 0.0),\n",
       " ('fr_sulfonamd', 0.0),\n",
       " ('fr_sulfone', 0.0),\n",
       " ('fr_term_acetylene', 0.0),\n",
       " ('fr_tetrazole', 0.0),\n",
       " ('fr_thiocyan', 0.0),\n",
       " ('fr_unbrch_alkane', 0.0),\n",
       " ('fr_urea', 0.0),\n",
       " ('fr_ketone_Topliss', 0.0),\n",
       " ('feat_002', 0.0),\n",
       " ('feat_003', 0.0),\n",
       " ('feat_004', 0.0),\n",
       " ('feat_008', 0.0),\n",
       " ('feat_009', 0.0),\n",
       " ('feat_010', 0.0),\n",
       " ('feat_011', 0.0),\n",
       " ('feat_012', 0.0),\n",
       " ('feat_013', 0.0),\n",
       " ('feat_014', 0.0),\n",
       " ('feat_015', 0.0),\n",
       " ('feat_016', 0.0),\n",
       " ('feat_017', 0.0),\n",
       " ('feat_018', 0.0),\n",
       " ('feat_019', 0.0),\n",
       " ('feat_020', 0.0),\n",
       " ('feat_021', 0.0),\n",
       " ('feat_022', 0.0),\n",
       " ('feat_023', 0.0),\n",
       " ('feat_024', 0.0),\n",
       " ('feat_026', 0.0),\n",
       " ('feat_027', 0.0),\n",
       " ('feat_028', 0.0),\n",
       " ('feat_029', 0.0),\n",
       " ('feat_030', 0.0),\n",
       " ('feat_031', 0.0),\n",
       " ('feat_032', 0.0),\n",
       " ('feat_033', 0.0),\n",
       " ('feat_034', 0.0),\n",
       " ('feat_035', 0.0),\n",
       " ('feat_036', 0.0),\n",
       " ('feat_038', 0.0),\n",
       " ('feat_039', 0.0),\n",
       " ('feat_040', 0.0),\n",
       " ('feat_041', 0.0),\n",
       " ('feat_042', 0.0),\n",
       " ('feat_043', 0.0),\n",
       " ('feat_045', 0.0),\n",
       " ('feat_046', 0.0),\n",
       " ('feat_047', 0.0),\n",
       " ('feat_048', 0.0),\n",
       " ('feat_049', 0.0),\n",
       " ('feat_050', 0.0),\n",
       " ('feat_051', 0.0),\n",
       " ('feat_052', 0.0),\n",
       " ('feat_053', 0.0),\n",
       " ('feat_054', 0.0),\n",
       " ('feat_055', 0.0),\n",
       " ('feat_056', 0.0),\n",
       " ('feat_057', 0.0),\n",
       " ('feat_058', 0.0),\n",
       " ('feat_059', 0.0),\n",
       " ('feat_060', 0.0),\n",
       " ('feat_061', 0.0),\n",
       " ('feat_062', 0.0),\n",
       " ('feat_063', 0.0),\n",
       " ('feat_064', 0.0),\n",
       " ('feat_065', 0.0),\n",
       " ('feat_066', 0.0),\n",
       " ('feat_067', 0.0),\n",
       " ('feat_070', 0.0),\n",
       " ('feat_071', 0.0),\n",
       " ('feat_073', 0.0),\n",
       " ('feat_074', 0.0),\n",
       " ('feat_075', 0.0),\n",
       " ('feat_076', 0.0),\n",
       " ('feat_077', 0.0),\n",
       " ('feat_078', 0.0),\n",
       " ('feat_079', 0.0),\n",
       " ('feat_080', 0.0),\n",
       " ('feat_081', 0.0),\n",
       " ('feat_082', 0.0),\n",
       " ('feat_083', 0.0),\n",
       " ('feat_084', 0.0),\n",
       " ('feat_085', 0.0),\n",
       " ('feat_086', 0.0),\n",
       " ('feat_088', 0.0),\n",
       " ('feat_089', 0.0),\n",
       " ('feat_091', 0.0),\n",
       " ('feat_092', 0.0),\n",
       " ('feat_093', 0.0),\n",
       " ('feat_094', 0.0),\n",
       " ('feat_095', 0.0),\n",
       " ('feat_096', 0.0),\n",
       " ('feat_097', 0.0),\n",
       " ('feat_098', 0.0),\n",
       " ('feat_099', 0.0),\n",
       " ('feat_100', 0.0),\n",
       " ('feat_101', 0.0),\n",
       " ('feat_103', 0.0),\n",
       " ('feat_104', 0.0),\n",
       " ('feat_105', 0.0),\n",
       " ('feat_106', 0.0),\n",
       " ('feat_107', 0.0),\n",
       " ('feat_108', 0.0),\n",
       " ('feat_109', 0.0),\n",
       " ('feat_110', 0.0),\n",
       " ('feat_111', 0.0),\n",
       " ('feat_112', 0.0),\n",
       " ('feat_113', 0.0),\n",
       " ('feat_114', 0.0),\n",
       " ('feat_115', 0.0),\n",
       " ('feat_116', 0.0),\n",
       " ('feat_117', 0.0),\n",
       " ('feat_118', 0.0),\n",
       " ('feat_120', 0.0),\n",
       " ('feat_121', 0.0),\n",
       " ('feat_122', 0.0),\n",
       " ('feat_124', 0.0),\n",
       " ('feat_125', 0.0),\n",
       " ('feat_127', 0.0),\n",
       " ('feat_128', 0.0),\n",
       " ('feat_129', 0.0),\n",
       " ('feat_130', 0.0),\n",
       " ('feat_131', 0.0),\n",
       " ('feat_133', 0.0),\n",
       " ('feat_134', 0.0),\n",
       " ('feat_135', 0.0),\n",
       " ('feat_136', 0.0),\n",
       " ('feat_137', 0.0),\n",
       " ('feat_138', 0.0),\n",
       " ('feat_139', 0.0),\n",
       " ('feat_140', 0.0),\n",
       " ('feat_141', 0.0),\n",
       " ('feat_142', 0.0),\n",
       " ('feat_143', 0.0),\n",
       " ('feat_144', 0.0),\n",
       " ('feat_145', 0.0),\n",
       " ('feat_146', 0.0),\n",
       " ('feat_147', 0.0),\n",
       " ('feat_148', 0.0),\n",
       " ('feat_149', 0.0),\n",
       " ('feat_150', 0.0),\n",
       " ('feat_151', 0.0),\n",
       " ('feat_152', 0.0),\n",
       " ('feat_153', 0.0),\n",
       " ('feat_154', 0.0),\n",
       " ('feat_155', 0.0),\n",
       " ('feat_156', 0.0),\n",
       " ('feat_157', 0.0),\n",
       " ('feat_158', 0.0),\n",
       " ('feat_159', 0.0),\n",
       " ('feat_160', 0.0),\n",
       " ('feat_161', 0.0),\n",
       " ('feat_162', 0.0),\n",
       " ('feat_163', 0.0),\n",
       " ('feat_164', 0.0),\n",
       " ('feat_165', 0.0),\n",
       " ('feat_166', 0.0),\n",
       " ('feat_167', 0.0),\n",
       " ('feat_168', 0.0),\n",
       " ('feat_169', 0.0),\n",
       " ('feat_170', 0.0),\n",
       " ('feat_171', 0.0),\n",
       " ('feat_172', 0.0),\n",
       " ('feat_174', 0.0),\n",
       " ('feat_175', 0.0),\n",
       " ('feat_177', 0.0),\n",
       " ('feat_178', 0.0),\n",
       " ('feat_179', 0.0),\n",
       " ('feat_180', 0.0),\n",
       " ('feat_181', 0.0),\n",
       " ('feat_182', 0.0),\n",
       " ('feat_183', 0.0),\n",
       " ('feat_184', 0.0),\n",
       " ('feat_185', 0.0),\n",
       " ('feat_186', 0.0),\n",
       " ('feat_188', 0.0),\n",
       " ('feat_189', 0.0),\n",
       " ('feat_190', 0.0),\n",
       " ('feat_191', 0.0),\n",
       " ('feat_192', 0.0),\n",
       " ('feat_193', 0.0),\n",
       " ('feat_194', 0.0),\n",
       " ('feat_195', 0.0),\n",
       " ('feat_197', 0.0),\n",
       " ('feat_198', 0.0),\n",
       " ('feat_201', 0.0),\n",
       " ('feat_202', 0.0),\n",
       " ('feat_203', 0.0),\n",
       " ('feat_204', 0.0),\n",
       " ('feat_205', 0.0),\n",
       " ('feat_206', 0.0),\n",
       " ('feat_207', 0.0),\n",
       " ('feat_209', 0.0),\n",
       " ('feat_210', 0.0),\n",
       " ('feat_211', 0.0),\n",
       " ('feat_212', 0.0),\n",
       " ('feat_213', 0.0),\n",
       " ('feat_214', 0.0),\n",
       " ('feat_215', 0.0),\n",
       " ('feat_216', 0.0),\n",
       " ('feat_217', 0.0),\n",
       " ('feat_219', 0.0),\n",
       " ('feat_220', 0.0),\n",
       " ('feat_221', 0.0),\n",
       " ('feat_222', 0.0),\n",
       " ('feat_223', 0.0),\n",
       " ('feat_224', 0.0),\n",
       " ('feat_227', 0.0),\n",
       " ('feat_228', 0.0),\n",
       " ('feat_229', 0.0),\n",
       " ('feat_230', 0.0),\n",
       " ('feat_231', 0.0),\n",
       " ('feat_232', 0.0),\n",
       " ('feat_233', 0.0),\n",
       " ('feat_234', 0.0),\n",
       " ('feat_235', 0.0),\n",
       " ('feat_236', 0.0),\n",
       " ('feat_237', 0.0),\n",
       " ('feat_238', 0.0),\n",
       " ('feat_239', 0.0),\n",
       " ('feat_240', 0.0),\n",
       " ('feat_241', 0.0),\n",
       " ('feat_242', 0.0),\n",
       " ('feat_244', 0.0),\n",
       " ('feat_245', 0.0),\n",
       " ('feat_246', 0.0),\n",
       " ('feat_247', 0.0),\n",
       " ('feat_249', 0.0),\n",
       " ('feat_250', 0.0),\n",
       " ('feat_253', 0.0),\n",
       " ('feat_254', 0.0),\n",
       " ('feat_255', 0.0),\n",
       " ('feat_256', 0.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get feature names and importances\n",
    "feats = zip(df_train.columns, rf_est.feature_importances_)\n",
    "feats = sorted(feats, key=lambda x: x[1], reverse=True)\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fr_bicyclic',\n",
       " 'num_heteroatoms',\n",
       " 'feat_025',\n",
       " 'num_valence_electrons',\n",
       " 'feat_102',\n",
       " 'exact_molecular_weight',\n",
       " 'avg_molecular_weight',\n",
       " 'feat_119',\n",
       " 'num_branches',\n",
       " 'avg_molecular_weight_ignore_hydrogen',\n",
       " 'num_num_rotatable_bonds',\n",
       " 'num_h_acceptors',\n",
       " 'fr_NH0',\n",
       " 'feat_218',\n",
       " 'num_double_bonds',\n",
       " 'sssr',\n",
       " 'num_aliphatic_rings',\n",
       " 'fr_Ar_N',\n",
       " 'ring_count',\n",
       " 'fr_pyridine',\n",
       " 'num_aromatic_heterocycles',\n",
       " 'num_aliphatic_heterocycles',\n",
       " 'feat_251',\n",
       " 'fr_allylic_oxid',\n",
       " 'num_aromatic_carbocycles')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select top 25 ranked features\n",
    "top_feats = zip(*feats[:25])[0]\n",
    "top_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create interaction terms (e.g. x_1 * x_2) for all top features\n",
    "for i in range(len(top_feats)):\n",
    "    for j in range(i+1,len(top_feats)):\n",
    "        feat_i = top_feats[i]\n",
    "        feat_j = top_feats[j]\n",
    "        df_train[feat_i+'-'+feat_j] = df_train[feat_i]*df_train[feat_j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['smiles'] = smiles\n",
    "df_train['gap'] = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('FINAL_train_25_interactions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Add features for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"FINAL_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create interaction terms (e.g. x_1 * x_2) for all top features\n",
    "for i in range(len(top_feats)):\n",
    "    for j in range(i+1,len(top_feats)):\n",
    "        feat_i = top_feats[i]\n",
    "        feat_j = top_feats[j]\n",
    "        df_test[feat_i+'-'+feat_j] = df_test[feat_i]*df_test[feat_j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>num_branches</th>\n",
       "      <th>has_benzothiophene</th>\n",
       "      <th>has_carbazole</th>\n",
       "      <th>has_fluorene</th>\n",
       "      <th>num_double_bonds</th>\n",
       "      <th>avg_molecular_weight</th>\n",
       "      <th>exact_molecular_weight</th>\n",
       "      <th>avg_molecular_weight_ignore_hydrogen</th>\n",
       "      <th>num_valence_electrons</th>\n",
       "      <th>...</th>\n",
       "      <th>num_aromatic_heterocycles-num_aliphatic_heterocycles</th>\n",
       "      <th>num_aromatic_heterocycles-feat_251</th>\n",
       "      <th>num_aromatic_heterocycles-fr_allylic_oxid</th>\n",
       "      <th>num_aromatic_heterocycles-num_aromatic_carbocycles</th>\n",
       "      <th>num_aliphatic_heterocycles-feat_251</th>\n",
       "      <th>num_aliphatic_heterocycles-fr_allylic_oxid</th>\n",
       "      <th>num_aliphatic_heterocycles-num_aromatic_carbocycles</th>\n",
       "      <th>feat_251-fr_allylic_oxid</th>\n",
       "      <th>feat_251-num_aromatic_carbocycles</th>\n",
       "      <th>fr_allylic_oxid-num_aromatic_carbocycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>409.499</td>\n",
       "      <td>409.045587</td>\n",
       "      <td>398.411</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>352.469</td>\n",
       "      <td>351.991109</td>\n",
       "      <td>344.405</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>514.569</td>\n",
       "      <td>514.948537</td>\n",
       "      <td>501.465</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>376.491</td>\n",
       "      <td>376.103190</td>\n",
       "      <td>360.363</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>569.637</td>\n",
       "      <td>569.844956</td>\n",
       "      <td>559.557</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  num_branches  has_benzothiophene  has_carbazole  has_fluorene  \\\n",
       "0   1             2                   0              0             0   \n",
       "1   2             0                   0              0             0   \n",
       "2   3             1                   0              0             0   \n",
       "3   4             2                   0              0             0   \n",
       "4   5             3                   0              0             0   \n",
       "\n",
       "   num_double_bonds  avg_molecular_weight  exact_molecular_weight  \\\n",
       "0                 0               409.499              409.045587   \n",
       "1                 0               352.469              351.991109   \n",
       "2                 2               514.569              514.948537   \n",
       "3                 4               376.491              376.103190   \n",
       "4                 0               569.637              569.844956   \n",
       "\n",
       "   avg_molecular_weight_ignore_hydrogen  num_valence_electrons  \\\n",
       "0                               398.411                    136   \n",
       "1                               344.405                    110   \n",
       "2                               501.465                    146   \n",
       "3                               360.363                    132   \n",
       "4                               559.557                    154   \n",
       "\n",
       "                     ...                     \\\n",
       "0                    ...                      \n",
       "1                    ...                      \n",
       "2                    ...                      \n",
       "3                    ...                      \n",
       "4                    ...                      \n",
       "\n",
       "   num_aromatic_heterocycles-num_aliphatic_heterocycles  \\\n",
       "0                                                  0      \n",
       "1                                                  0      \n",
       "2                                                  4      \n",
       "3                                                  3      \n",
       "4                                                  0      \n",
       "\n",
       "   num_aromatic_heterocycles-feat_251  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "\n",
       "   num_aromatic_heterocycles-fr_allylic_oxid  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "\n",
       "   num_aromatic_heterocycles-num_aromatic_carbocycles  \\\n",
       "0                                                 10    \n",
       "1                                                  5    \n",
       "2                                                 12    \n",
       "3                                                  6    \n",
       "4                                                  0    \n",
       "\n",
       "   num_aliphatic_heterocycles-feat_251  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "\n",
       "   num_aliphatic_heterocycles-fr_allylic_oxid  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "\n",
       "   num_aliphatic_heterocycles-num_aromatic_carbocycles  \\\n",
       "0                                                  0     \n",
       "1                                                  0     \n",
       "2                                                  3     \n",
       "3                                                  2     \n",
       "4                                                  0     \n",
       "\n",
       "   feat_251-fr_allylic_oxid  feat_251-num_aromatic_carbocycles  \\\n",
       "0                         0                                  0   \n",
       "1                         0                                  0   \n",
       "2                         0                                  0   \n",
       "3                         0                                  0   \n",
       "4                         0                                  0   \n",
       "\n",
       "   fr_allylic_oxid-num_aromatic_carbocycles  \n",
       "0                                         0  \n",
       "1                                         0  \n",
       "2                                         0  \n",
       "3                                         0  \n",
       "4                                         0  \n",
       "\n",
       "[5 rows x 671 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.to_csv('FINAL_test_25_interactions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split training data into training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('FINAL_train_25_interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (999997, 669)\n",
      "Train gap: (999997,)\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'smiles' column \n",
    "df_train = df_train.drop(['smiles'], axis=1)\n",
    "\n",
    "# Store gap values\n",
    "Y_train = df_train.gap.values\n",
    "\n",
    "# Delete 'gap' column\n",
    "df_train = df_train.drop(['gap'], axis=1)\n",
    "X_train = df_train.values\n",
    "print \"Train features:\", X_train.shape\n",
    "print \"Train gap:\", Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Partition Training Data into Training, Validation\n",
    "cross_X_train, cross_X_valid, cross_Y_train, cross_Y_valid = train_test_split(X_train, Y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Selection -  Test various models\n",
    "#### A. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit Linear Regression to cross_X_train and validate it on validations set\n",
    "LR = LinearRegression()\n",
    "LR.fit(cross_X_train, cross_Y_train)\n",
    "LR_pred = LR.predict(cross_X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of coefficients that are zero: 79\n",
      "Total number of coefficients: 669\n",
      "[276, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 309, 310, 313, 314, 315, 316, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 361, 362, 365, 366, 367, 368]\n"
     ]
    }
   ],
   "source": [
    "LR.coef_\n",
    "zero_coefs = []\n",
    "for i in xrange(len(LR.coef_)):\n",
    "    if LR.coef_[i] == 0:\n",
    "        zero_coefs.append(i)\n",
    "print \"Number of coefficients that are zero:\", len(zero_coefs)\n",
    "print \"Total number of coefficients:\", len(LR.coef_)\n",
    "print zero_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.41847547  1.97750314  1.77424319 ...,  1.88201698  1.78367074\n",
      "  2.14235671]\n"
     ]
    }
   ],
   "source": [
    "print LR_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16509869307012576"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(cross_Y_valid, LR_pred)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Transform data using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=60)\n",
    "cross_X_train_transf = pca.fit_transform(cross_X_train)\n",
    "cross_X_valid_transf = pca.transform(cross_X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No PCA, Random Forest, feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=128, n_jobs=2, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train rf regressor\n",
    "rf_est = RandomForestRegressor(n_estimators=128,n_jobs=2, max_features='sqrt')\n",
    "rf_est.fit(cross_X_train, cross_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_pred = rf_est.predict(cross_X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14326511933024585"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE\n",
    "mean_squared_error(cross_Y_valid, rf_pred)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Random Forest (extra trees) using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extraTrees_pca = ExtraTreesRegressor(n_estimators=100,n_jobs=2)\n",
    "tree_est_wPCA = extraTrees_pca.fit(cross_X_train_transf, cross_Y_train)\n",
    "pca_exTree_pred = tree_est_wPCA.predict(cross_X_valid_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "mean_squared_error(cross_Y_valid, pca_exTree_pred)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D1. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set parameters to test\n",
    "# alphas = np.logspace(-4, -.5, 30) alpha = 0.0001 was best with RMSE of 0.25\n",
    "alphas = [.5,.1,.01,.001,.0001,.00001]\n",
    "\n",
    "# Initialize minimums \n",
    "\n",
    "minimum_alpha = 100\n",
    "minimum_RMSE = 100\n",
    "for alpha in alphas:\n",
    "    \n",
    "    # Fit model and predict on validation\n",
    "    clf = linear_model.Lasso(alpha=alpha)\n",
    "    clf.fit(cross_X_train,cross_Y_train)\n",
    "    y_pred = clf.predict(cross_X_valid) \n",
    "    \n",
    "    # Calculate RMSE and update minimum RMSE if possible\n",
    "    RMSE = np.sqrt(mean_squared_error(cross_Y_valid, y_pred))\n",
    "    if RMSE < minimum_RMSE:\n",
    "        minimum_RMSE = RMSE\n",
    "        minimum_alpha = alpha\n",
    "    \n",
    "print \"minimum RMSE is\", minimum_RMSE\n",
    "print \"minimum alpha is\",minimum_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D2. Lasso using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set parameters to test\n",
    "# alphas = np.logspace(-4, -.5, 30) alpha = 0.0001 was best with RMSE of 0.25\n",
    "alphas = [.5,.1,.01,.001,.0001,.00001]\n",
    "\n",
    "# Initialize minimums \n",
    "\n",
    "minimum_alpha = 100\n",
    "minimum_RMSE = 100\n",
    "for alpha in alphas:\n",
    "    \n",
    "    # Fit model and predict on validation\n",
    "    clf = linear_model.Lasso(alpha=alpha)\n",
    "    clf.fit(cross_X_train_transf,cross_Y_train)\n",
    "    y_pred = clf.predict(cross_X_valid_transf) \n",
    "    \n",
    "    # Calculate RMSE and update minimum RMSE if possible\n",
    "    RMSE = np.sqrt(mean_squared_error(cross_Y_valid, y_pred))\n",
    "    if RMSE < minimum_RMSE:\n",
    "        minimum_RMSE = RMSE\n",
    "        minimum_alpha = alpha\n",
    "    \n",
    "print \"minimum RMSE is\", minimum_RMSE\n",
    "print \"minimum alpha is\",minimum_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D1. Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set parameters to test\n",
    "alphas = [.5,.1,.01,.001,.0001,.00001] \n",
    "ratios = [.5,.1,.01,.001,.0001,.00001]\n",
    "counter = 0\n",
    "\n",
    "# Initialize minimums\n",
    "minimum_alpha = 100\n",
    "minimum_ratio = 100\n",
    "minimum_RMSE = 100\n",
    "for alpha in alphas:\n",
    "    for ratio in ratios:\n",
    "        \n",
    "        # Fit model and predict on validation\n",
    "        clf = linear_model.ElasticNet(alpha=alpha, l1_ratio=ratio)\n",
    "        clf.fit(cross_X_train,cross_Y_train)\n",
    "        y_pred = clf.predict(cross_X_valid) \n",
    "        \n",
    "        # Calculate RMSE and update minimum RMSE if possible\n",
    "        RMSE = np.sqrt(mean_squared_error(cross_Y_valid, y_pred))\n",
    "        if RMSE < minimum_RMSE:\n",
    "            minimum_RMSE = RMSE\n",
    "            minimum_alpha = alpha\n",
    "            minimum_ratio = ratio\n",
    "    counter +=1\n",
    "    print counter\n",
    "print \"minimum RMSE is\", minimum_RMSE\n",
    "print \"minimum alpha is\",minimum_alpha\n",
    "print \"minimum ratio is\",minimum_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D2. Elastic Net using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set parameters to test\n",
    "alphas = [.5,.1,.01,.001,.0001,.00001] \n",
    "ratios = [.5,.1,.01,.001,.0001,.00001]\n",
    "\n",
    "# Initialize minimums\n",
    "minimum_alpha = 100\n",
    "minimum_ratio = 100\n",
    "minimum_RMSE = 100\n",
    "for alpha in alphas:\n",
    "    for ratio in ratios:\n",
    "        \n",
    "        # Fit model and predict on validation\n",
    "        clf = linear_model.ElasticNet(alpha=alpha, l1_ratio=ratio)\n",
    "        clf.fit(cross_X_train_transf,cross_Y_train)\n",
    "        y_pred = clf.predict(cross_X_valid_transf) \n",
    "        \n",
    "        # Calculate RMSE and update minimum RMSE if possible\n",
    "        RMSE = np.sqrt(mean_squared_error(cross_Y_valid, y_pred))\n",
    "        if RMSE < minimum_RMSE:\n",
    "            minimum_RMSE = RMSE\n",
    "            minimum_alpha = alpha\n",
    "            minimum_ratio = ratio\n",
    "\n",
    "print \"minimum RMSE is\", minimum_RMSE\n",
    "print \"minimum alpha is\",minimum_alpha\n",
    "print \"minimum ratio is\",minimum_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove cross validation datasets\n",
    "del cross_X_train, cross_X_valid, cross_Y_train, cross_Y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# V. Final Model Construction and Test Set Prediction \n",
    "1. Read in training data\n",
    "2. Read in test data\n",
    "3. If using PCA, transform training and test data\n",
    "4. Train model using training data\n",
    "5. Predict output using test data\n",
    "6. Write output to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('FINAL_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#delete 'Id' column\n",
    "df_test = df_test.drop(['Id'], axis=1)\n",
    "# Drop the 'smiles' column\n",
    "df_test= df_test.drop(['smiles'], axis=1)\n",
    "X_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=60)\n",
    "extraTrees_pca = ExtraTreesRegressor(n_estimators=100,n_jobs=2)\n",
    "# extraTrees = ExtraTreesRegressor(n_estimators=25,n_jobs=2)\n",
    "\n",
    "X_transf = pca.fit_transform(X_train)\n",
    "X_test_transf = pca.transform(X_test)\n",
    "\n",
    "tree_est_wPCA = extraTrees_pca.fit(X_transf, Y_train)\n",
    "# tree_estimator = extraTrees.fit(X_train, Y_train)\n",
    "\n",
    "pca_exTree_pred = tree_est_wPCA.predict(X_test_transf)\n",
    "# exTree_pred = tree_estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write to file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
