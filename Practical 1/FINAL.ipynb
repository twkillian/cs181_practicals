{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, ElasticNetCV, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rdkit import DataStructs, Chem\n",
    "from rdkit.Chem import AllChem, Descriptors, Lipinski, Fragments, rdmolops\n",
    "from rdkit.ML.Cluster import Butina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *IF FEATURE ENGINEERING IS DONE: DO NOT START HERE*\n",
    "# *SKIP TO THE START OF SECTION IV: MODEL SELECTION*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in training data\n",
    "df_train = pd.read_csv(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_002  \\\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...         0         0   \n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...         1         0   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...         1         0   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...         1         0   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1         0         0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008  feat_009  ...   \\\n",
       "0         0         0         1         0         1         0         0  ...    \n",
       "1         0         0         1         0         1         0         0  ...    \n",
       "2         0         0         1         1         1         0         0  ...    \n",
       "3         0         0         1         1         1         0         0  ...    \n",
       "4         0         0         1         0         1         0         0  ...    \n",
       "\n",
       "   feat_248  feat_249  feat_250  feat_251  feat_252  feat_253  feat_254  \\\n",
       "0         1         0         0         0         0         0         0   \n",
       "1         1         0         0         1         0         0         0   \n",
       "2         1         0         0         0         1         0         0   \n",
       "3         1         0         0         0         1         0         0   \n",
       "4         1         0         0         0         0         0         0   \n",
       "\n",
       "   feat_255  feat_256   gap  \n",
       "0         0         0  1.19  \n",
       "1         0         0  1.60  \n",
       "2         0         0  1.49  \n",
       "3         0         0  1.36  \n",
       "4         0         0  1.98  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   1.30000000e+01,\n",
       "          2.08000000e+02,   1.87700000e+03,   6.97100000e+03,\n",
       "          1.85790000e+04,   3.26720000e+04,   4.29330000e+04,\n",
       "          6.01070000e+04,   6.78140000e+04,   8.81420000e+04,\n",
       "          8.71470000e+04,   1.00516000e+05,   8.87370000e+04,\n",
       "          9.22500000e+04,   7.71080000e+04,   7.28620000e+04,\n",
       "          5.39310000e+04,   4.40760000e+04,   2.65580000e+04,\n",
       "          1.79800000e+04,   9.49400000e+03,   5.73300000e+03,\n",
       "          2.40600000e+03,   1.27500000e+03,   4.13000000e+02,\n",
       "          1.57000000e+02,   2.40000000e+01,   9.00000000e+00,\n",
       "          3.00000000e+00,   1.00000000e+00]),\n",
       " array([-1.44  , -1.3352, -1.2304, -1.1256, -1.0208, -0.916 , -0.8112,\n",
       "        -0.7064, -0.6016, -0.4968, -0.392 , -0.2872, -0.1824, -0.0776,\n",
       "         0.0272,  0.132 ,  0.2368,  0.3416,  0.4464,  0.5512,  0.656 ,\n",
       "         0.7608,  0.8656,  0.9704,  1.0752,  1.18  ,  1.2848,  1.3896,\n",
       "         1.4944,  1.5992,  1.704 ,  1.8088,  1.9136,  2.0184,  2.1232,\n",
       "         2.228 ,  2.3328,  2.4376,  2.5424,  2.6472,  2.752 ,  2.8568,\n",
       "         2.9616,  3.0664,  3.1712,  3.276 ,  3.3808,  3.4856,  3.5904,\n",
       "         3.6952,  3.8   ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEACAYAAACtVTGuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106bd2210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_train.gap.values, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "I see some outliers around -1.5.  Having negative values makes no sense, since the gap is highest - lowest -- they must be misrecorded.  ==> Remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove negative HOMO-LUMO gaps\n",
    "df_train = df_train[df_train['gap'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999997\n"
     ]
    }
   ],
   "source": [
    "print len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.00000000e+00,   3.00000000e+00,   1.00000000e+01,\n",
       "          6.80000000e+01,   3.46000000e+02,   1.03000000e+03,\n",
       "          3.10900000e+03,   5.69200000e+03,   1.16800000e+04,\n",
       "          1.52310000e+04,   2.31510000e+04,   2.45190000e+04,\n",
       "          2.82990000e+04,   3.82210000e+04,   3.75660000e+04,\n",
       "          4.99490000e+04,   4.69370000e+04,   5.92430000e+04,\n",
       "          5.27070000e+04,   6.31800000e+04,   5.51100000e+04,\n",
       "          6.23660000e+04,   5.13550000e+04,   5.81940000e+04,\n",
       "          4.73270000e+04,   4.41680000e+04,   4.62780000e+04,\n",
       "          3.57430000e+04,   3.51520000e+04,   2.52700000e+04,\n",
       "          2.32420000e+04,   1.51640000e+04,   1.31150000e+04,\n",
       "          8.26600000e+03,   6.79300000e+03,   4.05100000e+03,\n",
       "          3.17300000e+03,   1.67100000e+03,   1.03700000e+03,\n",
       "          7.96000000e+02,   3.72000000e+02,   2.42000000e+02,\n",
       "          9.00000000e+01,   5.30000000e+01,   1.40000000e+01,\n",
       "          6.00000000e+00,   3.00000000e+00,   3.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00]),\n",
       " array([ 0.57  ,  0.6346,  0.6992,  0.7638,  0.8284,  0.893 ,  0.9576,\n",
       "         1.0222,  1.0868,  1.1514,  1.216 ,  1.2806,  1.3452,  1.4098,\n",
       "         1.4744,  1.539 ,  1.6036,  1.6682,  1.7328,  1.7974,  1.862 ,\n",
       "         1.9266,  1.9912,  2.0558,  2.1204,  2.185 ,  2.2496,  2.3142,\n",
       "         2.3788,  2.4434,  2.508 ,  2.5726,  2.6372,  2.7018,  2.7664,\n",
       "         2.831 ,  2.8956,  2.9602,  3.0248,  3.0894,  3.154 ,  3.2186,\n",
       "         3.2832,  3.3478,  3.4124,  3.477 ,  3.5416,  3.6062,  3.6708,\n",
       "         3.7354,  3.8   ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEACAYAAABGYoqtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106bd2150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histogram of gaps without negative values\n",
    "plt.hist(df_train.gap.values, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Training Data Processing and Feature Engineering\n",
    "1. Drop all columns except smiles and gaps\n",
    "2. Add \"key\" column, partition the data, and save those partitions\n",
    "3. Remove all dataframes from memory\n",
    "4. Load each partition (1 by 1), perform feature engineering, and save each partition to a csv\n",
    "5. Reaggregate all partitions into one df, merge add binary-valued features from original training dataset, and save to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Drop all columns except smiles and gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles   gap\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...  1.19\n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...  1.60\n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...  1.49\n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...  1.36\n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1  1.98"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all columns except smiles and gaps\n",
    "df_train = df_train.drop(df_train.columns[range(1,257)], axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add \"key\" column, partition the data, and save those partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add key column\n",
    "df_train['key'] = df_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>gap</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles   gap  key\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...  1.19    0\n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...  1.60    1\n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...  1.49    2\n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...  1.36    3\n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1  1.98    4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_parts = 10\n",
    "df_train_parts = np.array_split(df_train, num_parts)\n",
    "for i in xrange(len(df_train_parts)):\n",
    "    df_train_parts[i].to_csv('smiles_gaps_keys_df_train_part_'+str(i)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Remove all dataframes from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_train\n",
    "del df_train_parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load each partition (1 by 1), perform feature engineering, and save each partition to a csv\n",
    "\n",
    "(http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/). \n",
    "\n",
    "#### Number of Branches\n",
    "The idea is that the number of  [branches](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system#Branching) influences the gap between HOMO and LUMO levels.\n",
    "\n",
    "#### Note: We pull the specific compounds of intereste from [this poster.](http://digitalscholarship.unlv.edu/cgi/viewcontent.cgi?article=1036&context=focs_ug_research)\n",
    "\n",
    "#### Benzene Ring\n",
    "The last feature is determining, from the SMILES encoding whether or not there is a benzene ring in the compound. Benzene rings are held together with pi bonds which are more conjugated (which means they are closer together in energy)\n",
    "\n",
    "#### Number of Double Bonds\n",
    "\n",
    "#### Additional Features engineered using from RDKit library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 0: finished initial feat gen\n",
      "Part 0: finished molecule generation\n",
      "Part 0: finished first feature\n",
      "Part 0: finished Descriptors and rdmolops\n",
      "Part 0: finished Lipinski\n",
      "Part 0: finished Fragments\n",
      "Part 1: finished initial feat gen\n",
      "Part 1: finished molecule generation\n",
      "Part 1: finished first feature\n",
      "Part 1: finished Descriptors and rdmolops\n",
      "Part 1: finished Lipinski\n",
      "Part 1: finished Fragments\n",
      "Part 2: finished initial feat gen\n",
      "Part 2: finished molecule generation\n",
      "Part 2: finished first feature\n",
      "Part 2: finished Descriptors and rdmolops\n",
      "Part 2: finished Lipinski\n",
      "Part 2: finished Fragments\n",
      "Part 3: finished initial feat gen\n",
      "Part 3: finished molecule generation\n",
      "Part 3: finished first feature\n",
      "Part 3: finished Descriptors and rdmolops\n",
      "Part 3: finished Lipinski\n",
      "Part 3: finished Fragments\n",
      "Part 4: finished initial feat gen\n",
      "Part 4: finished molecule generation\n",
      "Part 4: finished first feature\n",
      "Part 4: finished Descriptors and rdmolops\n",
      "Part 4: finished Lipinski\n",
      "Part 4: finished Fragments\n",
      "Part 5: finished initial feat gen\n",
      "Part 5: finished molecule generation\n",
      "Part 5: finished first feature\n",
      "Part 5: finished Descriptors and rdmolops\n",
      "Part 5: finished Lipinski\n",
      "Part 5: finished Fragments\n",
      "Part 6: finished initial feat gen\n",
      "Part 6: finished molecule generation\n",
      "Part 6: finished first feature\n",
      "Part 6: finished Descriptors and rdmolops\n",
      "Part 6: finished Lipinski\n",
      "Part 6: finished Fragments\n",
      "Part 7: finished initial feat gen\n",
      "Part 7: finished molecule generation\n",
      "Part 7: finished first feature\n",
      "Part 7: finished Descriptors and rdmolops\n",
      "Part 7: finished Lipinski\n",
      "Part 7: finished Fragments\n",
      "Part 8: finished initial feat gen\n",
      "Part 8: finished molecule generation\n",
      "Part 8: finished first feature\n",
      "Part 8: finished Descriptors and rdmolops\n",
      "Part 8: finished Lipinski\n",
      "Part 8: finished Fragments\n",
      "Part 9: finished initial feat gen\n",
      "Part 9: finished molecule generation\n",
      "Part 9: finished first feature\n",
      "Part 9: finished Descriptors and rdmolops\n",
      "Part 9: finished Lipinski\n",
      "Part 9: finished Fragments\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(num_parts):\n",
    "    df_train_part = pd.read_csv('smiles_gaps_keys_df_train_part_'+str(i)+'.csv')\n",
    "    \n",
    "    # Apply feature engineering to train data\n",
    "    num_branches = df_train_part.smiles.apply(lambda x: x.count('('))\n",
    "    has_benzothiophene = df_train_part.smiles.apply(lambda x: min(1,x.count('s2c1ccccc1cc2')))\n",
    "    has_carbazole = df_train_part.smiles.apply(lambda x: min(1,x.count('c1ccc2c(c1)c3ccccc3[nH]2')))\n",
    "    has_fluorene = df_train_part.smiles.apply(lambda x: min(1,x.count('c1ccc-2c(c1)Cc3c2cccc3')))\n",
    "    num_double_bonds = df_train_part.smiles.apply(lambda x: x.count('='))\n",
    "    df_train_part['num_branches'] = num_branches\n",
    "    df_train_part['has_benzothiophene'] = has_benzothiophene\n",
    "    df_train_part['has_carbazole'] = has_carbazole\n",
    "    df_train_part['has_fluorene'] = has_fluorene\n",
    "    df_train_part['num_double_bonds'] = num_double_bonds\n",
    "    print \"Part {}: finished initial feat gen\".format(i)\n",
    "    # RDKit Feature Engineering\n",
    "    # Generate molecule objects\n",
    "    molecules = df_train_part.smiles.apply(lambda x: Chem.MolFromSmiles(x))\n",
    "    print \"Part {}: finished molecule generation\".format(i)\n",
    "    # Generate Features\n",
    "    df_train_part['avg_molecular_weight'] = molecules.apply(lambda x: Descriptors.MolWt(x))\n",
    "    print \"Part {}: finished first feature\".format(i)\n",
    "    df_train_part['exact_molecular_weight'] = molecules.apply(lambda x: Descriptors.ExactMolWt(x))\n",
    "    df_train_part['avg_molecular_weight_ignore_hydrogen'] = molecules.apply(lambda x: Descriptors.HeavyAtomMolWt(x))\n",
    "    df_train_part['num_valence_electrons'] = molecules.apply(lambda x: Descriptors.NumValenceElectrons(x))\n",
    "    df_train_part['num_radical_electrons'] = molecules.apply(lambda x: Descriptors.NumRadicalElectrons(x))\n",
    "    df_train_part['formal_charge'] = molecules.apply(lambda x: rdmolops.GetFormalCharge(x))\n",
    "    df_train_part['sssr'] = molecules.apply(lambda x: rdmolops.GetSSSR(x))\n",
    "    print \"Part {}: finished Descriptors and rdmolops\".format(i)\n",
    "    df_train_part['fraction_csp3'] = molecules.apply(lambda x: Lipinski.FractionCSP3(x))\n",
    "    df_train_part['num_aliphatic_carbocycles'] = molecules.apply(lambda x: Lipinski.NumAliphaticCarbocycles(x))\n",
    "    df_train_part['num_aliphatic_heterocycles'] = molecules.apply(lambda x: Lipinski.NumAliphaticHeterocycles(x))\n",
    "    df_train_part['num_aliphatic_rings'] = molecules.apply(lambda x: Lipinski.NumAliphaticRings(x))\n",
    "    df_train_part['num_aromatic_carbocycles'] = molecules.apply(lambda x: Lipinski.NumAromaticCarbocycles(x))\n",
    "    df_train_part['num_aromatic_heterocycles'] = molecules.apply(lambda x: Lipinski.NumAromaticHeterocycles(x))\n",
    "    df_train_part['num_aromatic_rings'] = molecules.apply(lambda x: Lipinski.NumAromaticRings(x))\n",
    "    df_train_part['num_saturated_carbocycles'] = molecules.apply(lambda x: Lipinski.NumSaturatedCarbocycles(x))\n",
    "    df_train_part['num_saturated_heterocycles'] = molecules.apply(lambda x: Lipinski.NumSaturatedHeterocycles(x))\n",
    "    df_train_part['num_saturated_rings'] = molecules.apply(lambda x: Lipinski.NumSaturatedRings(x))\n",
    "    df_train_part['num_nh_oh'] = molecules.apply(lambda x: Lipinski.NHOHCount(x))\n",
    "    df_train_part['num_num_rotatable_bonds'] = molecules.apply(lambda x: Lipinski.NumRotatableBonds(x))\n",
    "    df_train_part['num_heteroatoms'] = molecules.apply(lambda x: Lipinski.NumHeteroatoms(x))\n",
    "    df_train_part['num_h_acceptors'] = molecules.apply(lambda x: Lipinski.NumHAcceptors(x))\n",
    "    df_train_part['num_h_donors'] = molecules.apply(lambda x: Lipinski.NumHDonors(x))\n",
    "    df_train_part['ring_count'] = molecules.apply(lambda x: Lipinski.RingCount(x))\n",
    "    print \"Part {}: finished Lipinski\".format(i)\n",
    "    # See Parsing_methods_from_rdk_source.ipynb\n",
    "    df_train_part['fr_Al_COO'] = molecules.apply(lambda x: Fragments.fr_Al_COO(x))\n",
    "    df_train_part['fr_Al_OH'] = molecules.apply(lambda x: Fragments.fr_Al_OH(x))\n",
    "    df_train_part['fr_Al_OH_noTert'] = molecules.apply(lambda x: Fragments.fr_Al_OH_noTert(x))\n",
    "    df_train_part['fr_ArN'] = molecules.apply(lambda x: Fragments.fr_ArN(x))\n",
    "    df_train_part['fr_Ar_COO'] = molecules.apply(lambda x: Fragments.fr_Ar_COO(x))\n",
    "    df_train_part['fr_Ar_N'] = molecules.apply(lambda x: Fragments.fr_Ar_N(x))\n",
    "    df_train_part['fr_Ar_NH'] = molecules.apply(lambda x: Fragments.fr_Ar_NH(x))\n",
    "    df_train_part['fr_Ar_OH'] = molecules.apply(lambda x: Fragments.fr_Ar_OH(x))\n",
    "    df_train_part['fr_COO'] = molecules.apply(lambda x: Fragments.fr_COO(x))\n",
    "    df_train_part['fr_COO2'] = molecules.apply(lambda x: Fragments.fr_COO2(x))\n",
    "    df_train_part['fr_C_O'] = molecules.apply(lambda x: Fragments.fr_C_O(x))\n",
    "    df_train_part['fr_C_O_noCOO'] = molecules.apply(lambda x: Fragments.fr_C_O_noCOO(x))\n",
    "    df_train_part['fr_C_S'] = molecules.apply(lambda x: Fragments.fr_C_S(x))\n",
    "    df_train_part['fr_HOCCN'] = molecules.apply(lambda x: Fragments.fr_HOCCN(x))\n",
    "    df_train_part['fr_Imine'] = molecules.apply(lambda x: Fragments.fr_Imine(x))\n",
    "    df_train_part['fr_NH0'] = molecules.apply(lambda x: Fragments.fr_NH0(x))\n",
    "    df_train_part['fr_NH1'] = molecules.apply(lambda x: Fragments.fr_NH1(x))\n",
    "    df_train_part['fr_NH2'] = molecules.apply(lambda x: Fragments.fr_NH2(x))\n",
    "    df_train_part['fr_N_O'] = molecules.apply(lambda x: Fragments.fr_N_O(x))\n",
    "    df_train_part['fr_Ndealkylation1'] = molecules.apply(lambda x: Fragments.fr_Ndealkylation1(x))\n",
    "    df_train_part['fr_Ndealkylation2'] = molecules.apply(lambda x: Fragments.fr_Ndealkylation2(x))\n",
    "    df_train_part['fr_Nhpyrrole'] = molecules.apply(lambda x: Fragments.fr_Nhpyrrole(x))\n",
    "    df_train_part['fr_SH'] = molecules.apply(lambda x: Fragments.fr_SH(x))\n",
    "    df_train_part['fr_aldehyde'] = molecules.apply(lambda x: Fragments.fr_aldehyde(x))\n",
    "    df_train_part['fr_alkyl_carbamate'] = molecules.apply(lambda x: Fragments.fr_alkyl_carbamate(x))\n",
    "    df_train_part['fr_alkyl_halide'] = molecules.apply(lambda x: Fragments.fr_alkyl_halide(x))\n",
    "    df_train_part['fr_allylic_oxid'] = molecules.apply(lambda x: Fragments.fr_allylic_oxid(x))\n",
    "    df_train_part['fr_amide'] = molecules.apply(lambda x: Fragments.fr_amide(x))\n",
    "    df_train_part['fr_amidine'] = molecules.apply(lambda x: Fragments.fr_amidine(x))\n",
    "    df_train_part['fr_aniline'] = molecules.apply(lambda x: Fragments.fr_aniline(x))\n",
    "    df_train_part['fr_aryl_methyl'] = molecules.apply(lambda x: Fragments.fr_aryl_methyl(x))\n",
    "    df_train_part['fr_azide'] = molecules.apply(lambda x: Fragments.fr_azide(x))\n",
    "    df_train_part['fr_azo'] = molecules.apply(lambda x: Fragments.fr_azo(x))\n",
    "    df_train_part['fr_barbitur'] = molecules.apply(lambda x: Fragments.fr_barbitur(x))\n",
    "    df_train_part['fr_benzene'] = molecules.apply(lambda x: Fragments.fr_benzene(x))\n",
    "    df_train_part['fr_benzodiazepine'] = molecules.apply(lambda x: Fragments.fr_benzodiazepine(x))\n",
    "    df_train_part['fr_bicyclic'] = molecules.apply(lambda x: Fragments.fr_bicyclic(x))\n",
    "    df_train_part['fr_diazo'] = molecules.apply(lambda x: Fragments.fr_diazo(x))\n",
    "    df_train_part['fr_dihydropyridine'] = molecules.apply(lambda x: Fragments.fr_dihydropyridine(x))\n",
    "    df_train_part['fr_epoxide'] = molecules.apply(lambda x: Fragments.fr_epoxide(x))\n",
    "    df_train_part['fr_ester'] = molecules.apply(lambda x: Fragments.fr_ester(x))\n",
    "    df_train_part['fr_ether'] = molecules.apply(lambda x: Fragments.fr_ether(x))\n",
    "    df_train_part['fr_furan'] = molecules.apply(lambda x: Fragments.fr_furan(x))\n",
    "    df_train_part['fr_guanido'] = molecules.apply(lambda x: Fragments.fr_guanido(x))\n",
    "    df_train_part['fr_halogen'] = molecules.apply(lambda x: Fragments.fr_halogen(x))\n",
    "    df_train_part['fr_hdrzine'] = molecules.apply(lambda x: Fragments.fr_hdrzine(x))\n",
    "    df_train_part['fr_hdrzone'] = molecules.apply(lambda x: Fragments.fr_hdrzone(x))\n",
    "    df_train_part['fr_imidazole'] = molecules.apply(lambda x: Fragments.fr_imidazole(x))\n",
    "    df_train_part['fr_imide'] = molecules.apply(lambda x: Fragments.fr_imide(x))\n",
    "    df_train_part['fr_isocyan'] = molecules.apply(lambda x: Fragments.fr_isocyan(x))\n",
    "    df_train_part['fr_isothiocyan'] = molecules.apply(lambda x: Fragments.fr_isothiocyan(x))\n",
    "    df_train_part['fr_ketone'] = molecules.apply(lambda x: Fragments.fr_ketone(x))\n",
    "    df_train_part['fr_lactam'] = molecules.apply(lambda x: Fragments.fr_lactam(x))\n",
    "    df_train_part['fr_lactone'] = molecules.apply(lambda x: Fragments.fr_lactone(x))\n",
    "    df_train_part['fr_methoxy'] = molecules.apply(lambda x: Fragments.fr_methoxy(x))\n",
    "    df_train_part['fr_morpholine'] = molecules.apply(lambda x: Fragments.fr_morpholine(x))\n",
    "    df_train_part['fr_nitrile'] = molecules.apply(lambda x: Fragments.fr_nitrile(x))\n",
    "    df_train_part['fr_nitro'] = molecules.apply(lambda x: Fragments.fr_nitro(x))\n",
    "    df_train_part['fr_nitro_arom'] = molecules.apply(lambda x: Fragments.fr_nitro_arom(x))\n",
    "    df_train_part['fr_nitro_arom_nonortho'] = molecules.apply(lambda x: Fragments.fr_nitro_arom_nonortho(x))\n",
    "    df_train_part['fr_nitroso'] = molecules.apply(lambda x: Fragments.fr_nitroso(x))\n",
    "    df_train_part['fr_oxazole'] = molecules.apply(lambda x: Fragments.fr_oxazole(x))\n",
    "    df_train_part['fr_oxime'] = molecules.apply(lambda x: Fragments.fr_oxime(x))\n",
    "    df_train_part['fr_para_hydroxylation'] = molecules.apply(lambda x: Fragments.fr_para_hydroxylation(x))\n",
    "    df_train_part['fr_phenol'] = molecules.apply(lambda x: Fragments.fr_phenol(x))\n",
    "    df_train_part['fr_phenol_noOrthoHbond'] = molecules.apply(lambda x: Fragments.fr_phenol_noOrthoHbond(x))\n",
    "    df_train_part['fr_phos_acid'] = molecules.apply(lambda x: Fragments.fr_phos_acid(x))\n",
    "    df_train_part['fr_phos_ester'] = molecules.apply(lambda x: Fragments.fr_phos_ester(x))\n",
    "    df_train_part['fr_piperdine'] = molecules.apply(lambda x: Fragments.fr_piperdine(x))\n",
    "    df_train_part['fr_piperzine'] = molecules.apply(lambda x: Fragments.fr_piperzine(x))\n",
    "    df_train_part['fr_priamide'] = molecules.apply(lambda x: Fragments.fr_priamide(x))\n",
    "    df_train_part['fr_prisulfonamd'] = molecules.apply(lambda x: Fragments.fr_prisulfonamd(x))\n",
    "    df_train_part['fr_pyridine'] = molecules.apply(lambda x: Fragments.fr_pyridine(x))\n",
    "    df_train_part['fr_quatN'] = molecules.apply(lambda x: Fragments.fr_quatN(x))\n",
    "    df_train_part['fr_sulfide'] = molecules.apply(lambda x: Fragments.fr_sulfide(x))\n",
    "    df_train_part['fr_sulfonamd'] = molecules.apply(lambda x: Fragments.fr_sulfonamd(x))\n",
    "    df_train_part['fr_sulfone'] = molecules.apply(lambda x: Fragments.fr_sulfone(x))\n",
    "    df_train_part['fr_term_acetylene'] = molecules.apply(lambda x: Fragments.fr_term_acetylene(x))\n",
    "    df_train_part['fr_tetrazole'] = molecules.apply(lambda x: Fragments.fr_tetrazole(x))\n",
    "    df_train_part['fr_thiazole'] = molecules.apply(lambda x: Fragments.fr_thiazole(x))\n",
    "    df_train_part['fr_thiocyan'] = molecules.apply(lambda x: Fragments.fr_thiocyan(x))\n",
    "    df_train_part['fr_thiophene'] = molecules.apply(lambda x: Fragments.fr_thiophene(x))\n",
    "    df_train_part['fr_unbrch_alkane'] = molecules.apply(lambda x: Fragments.fr_unbrch_alkane(x))\n",
    "    df_train_part['fr_urea'] = molecules.apply(lambda x: Fragments.fr_urea(x))\n",
    "    df_train_part['fr_ketone_Topliss'] = molecules.apply(lambda x: Fragments.fr_ketone_Topliss(x))\n",
    "    \n",
    "    print \"Part {}: finished Fragments\".format(i)\n",
    "    df_train_part.to_csv('rdk_feat_eng_df_train_part_'+str(i)+'.csv', index=False)\n",
    "    del df_train_part\n",
    "    del molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Reaggregate all partitions into one df, merge add binary-valued features from original training dataset, and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in each feature engineered partition\n",
    "df_train_parts = [pd.read_csv('rdk_feat_eng_df_train_part_'+str(i)+'.csv') for i in xrange(num_parts)]\n",
    "# concatenate them into one df\n",
    "df_train = pd.concat(df_train_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in old training\n",
    "# Note: df_train_old has same as before partitioning\n",
    "df_train_old = pd.read_csv(\"train.csv\")\n",
    "# Add key\n",
    "df_train_old['key'] = df_train_old.index\n",
    "# merge dataframes on 'key'\n",
    "df_train = df_train.merge(df_train_old, on=[\"key\"])\n",
    "# Fix columns\n",
    "df_train = df_train.drop(['gap_x'],axis=1)\n",
    "df_train = df_train.drop(['key'],axis=1)\n",
    "df_train = df_train.rename(columns = {'gap_y':'gap'})\n",
    "df_train = df_train.drop(['smiles_x'],axis=1)\n",
    "df_train = df_train.rename(columns = {'smiles_y':'smiles'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_branches</th>\n",
       "      <th>has_benzothiophene</th>\n",
       "      <th>has_carbazole</th>\n",
       "      <th>has_fluorene</th>\n",
       "      <th>num_double_bonds</th>\n",
       "      <th>avg_molecular_weight</th>\n",
       "      <th>exact_molecular_weight</th>\n",
       "      <th>avg_molecular_weight_ignore_hydrogen</th>\n",
       "      <th>num_valence_electrons</th>\n",
       "      <th>num_radical_electrons</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>470.462</td>\n",
       "      <td>470.907296</td>\n",
       "      <td>461.390</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>352.545</td>\n",
       "      <td>352.085202</td>\n",
       "      <td>336.417</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>399.576</td>\n",
       "      <td>399.032016</td>\n",
       "      <td>386.472</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>379.567</td>\n",
       "      <td>379.084867</td>\n",
       "      <td>362.431</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>396.391</td>\n",
       "      <td>396.042944</td>\n",
       "      <td>388.327</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_branches  has_benzothiophene  has_carbazole  has_fluorene  \\\n",
       "0             3                   0              0             0   \n",
       "1             1                   0              0             0   \n",
       "2             2                   0              0             0   \n",
       "3             1                   0              0             0   \n",
       "4             1                   0              0             0   \n",
       "\n",
       "   num_double_bonds  avg_molecular_weight  exact_molecular_weight  \\\n",
       "0                 0               470.462              470.907296   \n",
       "1                 5               352.545              352.085202   \n",
       "2                 1               399.576              399.032016   \n",
       "3                 4               379.567              379.084867   \n",
       "4                 0               396.391              396.042944   \n",
       "\n",
       "   avg_molecular_weight_ignore_hydrogen  num_valence_electrons  \\\n",
       "0                               461.390                    130   \n",
       "1                               336.417                    118   \n",
       "2                               386.472                    128   \n",
       "3                               362.431                    128   \n",
       "4                               388.327                    136   \n",
       "\n",
       "   num_radical_electrons  ...   feat_248  feat_249  feat_250  feat_251  \\\n",
       "0                      0  ...          1         0         0         0   \n",
       "1                      0  ...          1         0         0         1   \n",
       "2                      0  ...          1         0         0         0   \n",
       "3                      0  ...          1         0         0         0   \n",
       "4                      0  ...          1         0         0         0   \n",
       "\n",
       "   feat_252  feat_253  feat_254  feat_255  feat_256   gap  \n",
       "0         0         0         0         0         0  1.19  \n",
       "1         0         0         0         0         0  1.60  \n",
       "2         1         0         0         0         0  1.49  \n",
       "3         1         0         0         0         0  1.36  \n",
       "4         0         0         0         0         0  1.98  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save df_train\n",
    "df_train.to_csv('FINAL_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove df_train for now\n",
    "del df_train_parts\n",
    "del df_train_old\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Test Data Processing and Feature Engineering\n",
    "1. Drop all columns except smiles and ids\n",
    "2. Partition the data and save those partitions\n",
    "3. Remove all dataframes from memory\n",
    "4. Load each partition (1 by 1), perform feature engineering, and save each partition to a csv\n",
    "5. Reaggregate all partitions into one df, merge add binary-valued features from original test dataset, and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_247</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c1sc(-c2cnc3c(c2)c2nsnc2c2cc4cccnc4cc32)c2cc[n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[nH]1cccc1-c1cc2c3nsnc3c3c4sccc4[nH]c3c2s1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[nH]1c2cc(-c3ccc[se]3)c3nsnc3c2c2c3cscc3c3ccc4...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[nH]1c(cc2cnc3c(c12)c1=C[SiH2]C=c1c1ccc2=CCC=c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>c1sc(-c2sc(-c3sc(-c4scc5[se]ccc45)c4ccoc34)c3c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                             smiles  feat_001  feat_002  \\\n",
       "0   1  c1sc(-c2cnc3c(c2)c2nsnc2c2cc4cccnc4cc32)c2cc[n...         0         0   \n",
       "1   2         [nH]1cccc1-c1cc2c3nsnc3c3c4sccc4[nH]c3c2s1         0         0   \n",
       "2   3  [nH]1c2cc(-c3ccc[se]3)c3nsnc3c2c2c3cscc3c3ccc4...         1         0   \n",
       "3   4  [nH]1c(cc2cnc3c(c12)c1=C[SiH2]C=c1c1ccc2=CCC=c...         1         0   \n",
       "4   5  c1sc(-c2sc(-c3sc(-c4scc5[se]ccc45)c4ccoc34)c3c...         0         0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008    ...     \\\n",
       "0         0         0         1         1         1         0    ...      \n",
       "1         0         0         1         1         1         0    ...      \n",
       "2         0         0         1         1         1         0    ...      \n",
       "3         0         0         1         1         1         0    ...      \n",
       "4         0         0         1         0         1         0    ...      \n",
       "\n",
       "   feat_247  feat_248  feat_249  feat_250  feat_251  feat_252  feat_253  \\\n",
       "0         0         1         0         0         0         0         0   \n",
       "1         0         1         0         0         0         0         0   \n",
       "2         0         1         0         0         0         0         0   \n",
       "3         0         1         0         0         0         0         0   \n",
       "4         0         1         0         0         0         0         0   \n",
       "\n",
       "   feat_254  feat_255  feat_256  \n",
       "0         0         0         0  \n",
       "1         0         0         0  \n",
       "2         0         0         0  \n",
       "3         0         0         0  \n",
       "4         0         0         0  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in test data\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. Drop all columns except smiles and ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = df_test.drop(df_test.columns[range(2,258)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c1sc(-c2cnc3c(c2)c2nsnc2c2cc4cccnc4cc32)c2cc[n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[nH]1cccc1-c1cc2c3nsnc3c3c4sccc4[nH]c3c2s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[nH]1c2cc(-c3ccc[se]3)c3nsnc3c2c2c3cscc3c3ccc4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[nH]1c(cc2cnc3c(c12)c1=C[SiH2]C=c1c1ccc2=CCC=c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>c1sc(-c2sc(-c3sc(-c4scc5[se]ccc45)c4ccoc34)c3c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                             smiles\n",
       "0   1  c1sc(-c2cnc3c(c2)c2nsnc2c2cc4cccnc4cc32)c2cc[n...\n",
       "1   2         [nH]1cccc1-c1cc2c3nsnc3c3c4sccc4[nH]c3c2s1\n",
       "2   3  [nH]1c2cc(-c3ccc[se]3)c3nsnc3c2c2c3cscc3c3ccc4...\n",
       "3   4  [nH]1c(cc2cnc3c(c12)c1=C[SiH2]C=c1c1ccc2=CCC=c...\n",
       "4   5  c1sc(-c2sc(-c3sc(-c4scc5[se]ccc45)c4ccoc34)c3c..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Partition the data and save those partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_parts = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test_parts = np.array_split(df_test, num_parts)\n",
    "for i in xrange(num_parts):\n",
    "    df_test_parts[i].to_csv('smiles_and_ids_df_test_part_'+str(i)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Remove all dataframes from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_test\n",
    "del df_test_parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load each partition (1 by 1), perform feature engineering, and save each partition to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 0: finished initial feat gen\n",
      "Part 0: finished molecule generation\n",
      "Part 0: finished first feature\n",
      "Part 0: finished Descriptors and rdmolops\n",
      "Part 0: finished Lipinski\n",
      "Part 0: finished Fragments\n",
      "Part 1: finished initial feat gen\n",
      "Part 1: finished molecule generation\n",
      "Part 1: finished first feature\n",
      "Part 1: finished Descriptors and rdmolops\n",
      "Part 1: finished Lipinski\n",
      "Part 1: finished Fragments\n",
      "Part 2: finished initial feat gen\n",
      "Part 2: finished molecule generation\n",
      "Part 2: finished first feature\n",
      "Part 2: finished Descriptors and rdmolops\n",
      "Part 2: finished Lipinski\n",
      "Part 2: finished Fragments\n",
      "Part 3: finished initial feat gen\n",
      "Part 3: finished molecule generation\n",
      "Part 3: finished first feature\n",
      "Part 3: finished Descriptors and rdmolops\n",
      "Part 3: finished Lipinski\n",
      "Part 3: finished Fragments\n",
      "Part 4: finished initial feat gen\n",
      "Part 4: finished molecule generation\n",
      "Part 4: finished first feature\n",
      "Part 4: finished Descriptors and rdmolops\n",
      "Part 4: finished Lipinski\n",
      "Part 4: finished Fragments\n",
      "Part 5: finished initial feat gen\n",
      "Part 5: finished molecule generation\n",
      "Part 5: finished first feature\n",
      "Part 5: finished Descriptors and rdmolops\n",
      "Part 5: finished Lipinski\n",
      "Part 5: finished Fragments\n",
      "Part 6: finished initial feat gen\n",
      "Part 6: finished molecule generation\n",
      "Part 6: finished first feature\n",
      "Part 6: finished Descriptors and rdmolops\n",
      "Part 6: finished Lipinski\n",
      "Part 6: finished Fragments\n",
      "Part 7: finished initial feat gen\n",
      "Part 7: finished molecule generation\n",
      "Part 7: finished first feature\n",
      "Part 7: finished Descriptors and rdmolops\n",
      "Part 7: finished Lipinski\n",
      "Part 7: finished Fragments\n",
      "Part 8: finished initial feat gen\n",
      "Part 8: finished molecule generation\n",
      "Part 8: finished first feature\n",
      "Part 8: finished Descriptors and rdmolops\n",
      "Part 8: finished Lipinski\n",
      "Part 8: finished Fragments\n",
      "Part 9: finished initial feat gen\n",
      "Part 9: finished molecule generation\n",
      "Part 9: finished first feature\n",
      "Part 9: finished Descriptors and rdmolops\n",
      "Part 9: finished Lipinski\n",
      "Part 9: finished Fragments\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(num_parts):\n",
    "    df_test_part = pd.read_csv('smiles_and_ids_df_test_part_'+str(i)+'.csv')\n",
    "  \n",
    "\n",
    "    # Apply feature engineering to train data\n",
    "    num_branches = df_test_part.smiles.apply(lambda x: x.count('('))\n",
    "    has_benzothiophene = df_test_part.smiles.apply(lambda x: min(1,x.count('s2c1ccccc1cc2')))\n",
    "    has_carbazole = df_test_part.smiles.apply(lambda x: min(1,x.count('c1ccc2c(c1)c3ccccc3[nH]2')))\n",
    "    has_fluorene = df_test_part.smiles.apply(lambda x: min(1,x.count('c1ccc-2c(c1)Cc3c2cccc3')))\n",
    "    num_double_bonds = df_test_part.smiles.apply(lambda x: x.count('='))\n",
    "    df_test_part['num_branches'] = num_branches\n",
    "    df_test_part['has_benzothiophene'] = has_benzothiophene\n",
    "    df_test_part['has_carbazole'] = has_carbazole\n",
    "    df_test_part['has_fluorene'] = has_fluorene\n",
    "    df_test_part['num_double_bonds'] = num_double_bonds\n",
    "    print \"Part {}: finished initial feat gen\".format(i)\n",
    "    # RDKit Feature Engineering\n",
    "    # Generate molecule objects\n",
    "    molecules = df_test_part.smiles.apply(lambda x: Chem.MolFromSmiles(x))\n",
    "    print \"Part {}: finished molecule generation\".format(i)\n",
    "    # Generate Features\n",
    "    df_test_part['avg_molecular_weight'] = molecules.apply(lambda x: Descriptors.MolWt(x))\n",
    "    print \"Part {}: finished first feature\".format(i)\n",
    "    df_test_part['exact_molecular_weight'] = molecules.apply(lambda x: Descriptors.ExactMolWt(x))\n",
    "    df_test_part['avg_molecular_weight_ignore_hydrogen'] = molecules.apply(lambda x: Descriptors.HeavyAtomMolWt(x))\n",
    "    df_test_part['num_valence_electrons'] = molecules.apply(lambda x: Descriptors.NumValenceElectrons(x))\n",
    "    df_test_part['num_radical_electrons'] = molecules.apply(lambda x: Descriptors.NumRadicalElectrons(x))\n",
    "    df_test_part['formal_charge'] = molecules.apply(lambda x: rdmolops.GetFormalCharge(x))\n",
    "    df_test_part['sssr'] = molecules.apply(lambda x: rdmolops.GetSSSR(x))\n",
    "    print \"Part {}: finished Descriptors and rdmolops\".format(i)\n",
    "    df_test_part['fraction_csp3'] = molecules.apply(lambda x: Lipinski.FractionCSP3(x))\n",
    "    df_test_part['num_aliphatic_carbocycles'] = molecules.apply(lambda x: Lipinski.NumAliphaticCarbocycles(x))\n",
    "    df_test_part['num_aliphatic_heterocycles'] = molecules.apply(lambda x: Lipinski.NumAliphaticHeterocycles(x))\n",
    "    df_test_part['num_aliphatic_rings'] = molecules.apply(lambda x: Lipinski.NumAliphaticRings(x))\n",
    "    df_test_part['num_aromatic_carbocycles'] = molecules.apply(lambda x: Lipinski.NumAromaticCarbocycles(x))\n",
    "    df_test_part['num_aromatic_heterocycles'] = molecules.apply(lambda x: Lipinski.NumAromaticHeterocycles(x))\n",
    "    df_test_part['num_aromatic_rings'] = molecules.apply(lambda x: Lipinski.NumAromaticRings(x))\n",
    "    df_test_part['num_saturated_carbocycles'] = molecules.apply(lambda x: Lipinski.NumSaturatedCarbocycles(x))\n",
    "    df_test_part['num_saturated_heterocycles'] = molecules.apply(lambda x: Lipinski.NumSaturatedHeterocycles(x))\n",
    "    df_test_part['num_saturated_rings'] = molecules.apply(lambda x: Lipinski.NumSaturatedRings(x))\n",
    "    df_test_part['num_nh_oh'] = molecules.apply(lambda x: Lipinski.NHOHCount(x))\n",
    "    df_test_part['num_num_rotatable_bonds'] = molecules.apply(lambda x: Lipinski.NumRotatableBonds(x))\n",
    "    df_test_part['num_heteroatoms'] = molecules.apply(lambda x: Lipinski.NumHeteroatoms(x))\n",
    "    df_test_part['num_h_acceptors'] = molecules.apply(lambda x: Lipinski.NumHAcceptors(x))\n",
    "    df_test_part['num_h_donors'] = molecules.apply(lambda x: Lipinski.NumHDonors(x))\n",
    "    df_test_part['ring_count'] = molecules.apply(lambda x: Lipinski.RingCount(x))\n",
    "    print \"Part {}: finished Lipinski\".format(i)\n",
    "    # See Parsing_methods_from_rdk_source.ipynb\n",
    "    df_test_part['fr_Al_COO'] = molecules.apply(lambda x: Fragments.fr_Al_COO(x))\n",
    "    df_test_part['fr_Al_OH'] = molecules.apply(lambda x: Fragments.fr_Al_OH(x))\n",
    "    df_test_part['fr_Al_OH_noTert'] = molecules.apply(lambda x: Fragments.fr_Al_OH_noTert(x))\n",
    "    df_test_part['fr_ArN'] = molecules.apply(lambda x: Fragments.fr_ArN(x))\n",
    "    df_test_part['fr_Ar_COO'] = molecules.apply(lambda x: Fragments.fr_Ar_COO(x))\n",
    "    df_test_part['fr_Ar_N'] = molecules.apply(lambda x: Fragments.fr_Ar_N(x))\n",
    "    df_test_part['fr_Ar_NH'] = molecules.apply(lambda x: Fragments.fr_Ar_NH(x))\n",
    "    df_test_part['fr_Ar_OH'] = molecules.apply(lambda x: Fragments.fr_Ar_OH(x))\n",
    "    df_test_part['fr_COO'] = molecules.apply(lambda x: Fragments.fr_COO(x))\n",
    "    df_test_part['fr_COO2'] = molecules.apply(lambda x: Fragments.fr_COO2(x))\n",
    "    df_test_part['fr_C_O'] = molecules.apply(lambda x: Fragments.fr_C_O(x))\n",
    "    df_test_part['fr_C_O_noCOO'] = molecules.apply(lambda x: Fragments.fr_C_O_noCOO(x))\n",
    "    df_test_part['fr_C_S'] = molecules.apply(lambda x: Fragments.fr_C_S(x))\n",
    "    df_test_part['fr_HOCCN'] = molecules.apply(lambda x: Fragments.fr_HOCCN(x))\n",
    "    df_test_part['fr_Imine'] = molecules.apply(lambda x: Fragments.fr_Imine(x))\n",
    "    df_test_part['fr_NH0'] = molecules.apply(lambda x: Fragments.fr_NH0(x))\n",
    "    df_test_part['fr_NH1'] = molecules.apply(lambda x: Fragments.fr_NH1(x))\n",
    "    df_test_part['fr_NH2'] = molecules.apply(lambda x: Fragments.fr_NH2(x))\n",
    "    df_test_part['fr_N_O'] = molecules.apply(lambda x: Fragments.fr_N_O(x))\n",
    "    df_test_part['fr_Ndealkylation1'] = molecules.apply(lambda x: Fragments.fr_Ndealkylation1(x))\n",
    "    df_test_part['fr_Ndealkylation2'] = molecules.apply(lambda x: Fragments.fr_Ndealkylation2(x))\n",
    "    df_test_part['fr_Nhpyrrole'] = molecules.apply(lambda x: Fragments.fr_Nhpyrrole(x))\n",
    "    df_test_part['fr_SH'] = molecules.apply(lambda x: Fragments.fr_SH(x))\n",
    "    df_test_part['fr_aldehyde'] = molecules.apply(lambda x: Fragments.fr_aldehyde(x))\n",
    "    df_test_part['fr_alkyl_carbamate'] = molecules.apply(lambda x: Fragments.fr_alkyl_carbamate(x))\n",
    "    df_test_part['fr_alkyl_halide'] = molecules.apply(lambda x: Fragments.fr_alkyl_halide(x))\n",
    "    df_test_part['fr_allylic_oxid'] = molecules.apply(lambda x: Fragments.fr_allylic_oxid(x))\n",
    "    df_test_part['fr_amide'] = molecules.apply(lambda x: Fragments.fr_amide(x))\n",
    "    df_test_part['fr_amidine'] = molecules.apply(lambda x: Fragments.fr_amidine(x))\n",
    "    df_test_part['fr_aniline'] = molecules.apply(lambda x: Fragments.fr_aniline(x))\n",
    "    df_test_part['fr_aryl_methyl'] = molecules.apply(lambda x: Fragments.fr_aryl_methyl(x))\n",
    "    df_test_part['fr_azide'] = molecules.apply(lambda x: Fragments.fr_azide(x))\n",
    "    df_test_part['fr_azo'] = molecules.apply(lambda x: Fragments.fr_azo(x))\n",
    "    df_test_part['fr_barbitur'] = molecules.apply(lambda x: Fragments.fr_barbitur(x))\n",
    "    df_test_part['fr_benzene'] = molecules.apply(lambda x: Fragments.fr_benzene(x))\n",
    "    df_test_part['fr_benzodiazepine'] = molecules.apply(lambda x: Fragments.fr_benzodiazepine(x))\n",
    "    df_test_part['fr_bicyclic'] = molecules.apply(lambda x: Fragments.fr_bicyclic(x))\n",
    "    df_test_part['fr_diazo'] = molecules.apply(lambda x: Fragments.fr_diazo(x))\n",
    "    df_test_part['fr_dihydropyridine'] = molecules.apply(lambda x: Fragments.fr_dihydropyridine(x))\n",
    "    df_test_part['fr_epoxide'] = molecules.apply(lambda x: Fragments.fr_epoxide(x))\n",
    "    df_test_part['fr_ester'] = molecules.apply(lambda x: Fragments.fr_ester(x))\n",
    "    df_test_part['fr_ether'] = molecules.apply(lambda x: Fragments.fr_ether(x))\n",
    "    df_test_part['fr_furan'] = molecules.apply(lambda x: Fragments.fr_furan(x))\n",
    "    df_test_part['fr_guanido'] = molecules.apply(lambda x: Fragments.fr_guanido(x))\n",
    "    df_test_part['fr_halogen'] = molecules.apply(lambda x: Fragments.fr_halogen(x))\n",
    "    df_test_part['fr_hdrzine'] = molecules.apply(lambda x: Fragments.fr_hdrzine(x))\n",
    "    df_test_part['fr_hdrzone'] = molecules.apply(lambda x: Fragments.fr_hdrzone(x))\n",
    "    df_test_part['fr_imidazole'] = molecules.apply(lambda x: Fragments.fr_imidazole(x))\n",
    "    df_test_part['fr_imide'] = molecules.apply(lambda x: Fragments.fr_imide(x))\n",
    "    df_test_part['fr_isocyan'] = molecules.apply(lambda x: Fragments.fr_isocyan(x))\n",
    "    df_test_part['fr_isothiocyan'] = molecules.apply(lambda x: Fragments.fr_isothiocyan(x))\n",
    "    df_test_part['fr_ketone'] = molecules.apply(lambda x: Fragments.fr_ketone(x))\n",
    "    df_test_part['fr_lactam'] = molecules.apply(lambda x: Fragments.fr_lactam(x))\n",
    "    df_test_part['fr_lactone'] = molecules.apply(lambda x: Fragments.fr_lactone(x))\n",
    "    df_test_part['fr_methoxy'] = molecules.apply(lambda x: Fragments.fr_methoxy(x))\n",
    "    df_test_part['fr_morpholine'] = molecules.apply(lambda x: Fragments.fr_morpholine(x))\n",
    "    df_test_part['fr_nitrile'] = molecules.apply(lambda x: Fragments.fr_nitrile(x))\n",
    "    df_test_part['fr_nitro'] = molecules.apply(lambda x: Fragments.fr_nitro(x))\n",
    "    df_test_part['fr_nitro_arom'] = molecules.apply(lambda x: Fragments.fr_nitro_arom(x))\n",
    "    df_test_part['fr_nitro_arom_nonortho'] = molecules.apply(lambda x: Fragments.fr_nitro_arom_nonortho(x))\n",
    "    df_test_part['fr_nitroso'] = molecules.apply(lambda x: Fragments.fr_nitroso(x))\n",
    "    df_test_part['fr_oxazole'] = molecules.apply(lambda x: Fragments.fr_oxazole(x))\n",
    "    df_test_part['fr_oxime'] = molecules.apply(lambda x: Fragments.fr_oxime(x))\n",
    "    df_test_part['fr_para_hydroxylation'] = molecules.apply(lambda x: Fragments.fr_para_hydroxylation(x))\n",
    "    df_test_part['fr_phenol'] = molecules.apply(lambda x: Fragments.fr_phenol(x))\n",
    "    df_test_part['fr_phenol_noOrthoHbond'] = molecules.apply(lambda x: Fragments.fr_phenol_noOrthoHbond(x))\n",
    "    df_test_part['fr_phos_acid'] = molecules.apply(lambda x: Fragments.fr_phos_acid(x))\n",
    "    df_test_part['fr_phos_ester'] = molecules.apply(lambda x: Fragments.fr_phos_ester(x))\n",
    "    df_test_part['fr_piperdine'] = molecules.apply(lambda x: Fragments.fr_piperdine(x))\n",
    "    df_test_part['fr_piperzine'] = molecules.apply(lambda x: Fragments.fr_piperzine(x))\n",
    "    df_test_part['fr_priamide'] = molecules.apply(lambda x: Fragments.fr_priamide(x))\n",
    "    df_test_part['fr_prisulfonamd'] = molecules.apply(lambda x: Fragments.fr_prisulfonamd(x))\n",
    "    df_test_part['fr_pyridine'] = molecules.apply(lambda x: Fragments.fr_pyridine(x))\n",
    "    df_test_part['fr_quatN'] = molecules.apply(lambda x: Fragments.fr_quatN(x))\n",
    "    df_test_part['fr_sulfide'] = molecules.apply(lambda x: Fragments.fr_sulfide(x))\n",
    "    df_test_part['fr_sulfonamd'] = molecules.apply(lambda x: Fragments.fr_sulfonamd(x))\n",
    "    df_test_part['fr_sulfone'] = molecules.apply(lambda x: Fragments.fr_sulfone(x))\n",
    "    df_test_part['fr_term_acetylene'] = molecules.apply(lambda x: Fragments.fr_term_acetylene(x))\n",
    "    df_test_part['fr_tetrazole'] = molecules.apply(lambda x: Fragments.fr_tetrazole(x))\n",
    "    df_test_part['fr_thiazole'] = molecules.apply(lambda x: Fragments.fr_thiazole(x))\n",
    "    df_test_part['fr_thiocyan'] = molecules.apply(lambda x: Fragments.fr_thiocyan(x))\n",
    "    df_test_part['fr_thiophene'] = molecules.apply(lambda x: Fragments.fr_thiophene(x))\n",
    "    df_test_part['fr_unbrch_alkane'] = molecules.apply(lambda x: Fragments.fr_unbrch_alkane(x))\n",
    "    df_test_part['fr_urea'] = molecules.apply(lambda x: Fragments.fr_urea(x))\n",
    "    df_test_part['fr_ketone_Topliss'] = molecules.apply(lambda x: Fragments.fr_ketone_Topliss(x))\n",
    "    \n",
    "    print \"Part {}: finished Fragments\".format(i)\n",
    "    df_test_part.to_csv('rdk_feat_eng_df_test_part_'+str(i)+'.csv', index=False)\n",
    "    del df_test_part\n",
    "    del molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Reaggregate all partitions into one df, merge add binary-valued features from original test dataset, and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in each feat eng part\n",
    "df_test_parts = [pd.read_csv('rdk_feat_eng_df_test_part_'+str(i)+'.csv') for i in xrange(num_parts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine into one df\n",
    "df_test = pd.concat(df_test_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>num_branches</th>\n",
       "      <th>has_benzothiophene</th>\n",
       "      <th>has_carbazole</th>\n",
       "      <th>has_fluorene</th>\n",
       "      <th>num_double_bonds</th>\n",
       "      <th>avg_molecular_weight</th>\n",
       "      <th>exact_molecular_weight</th>\n",
       "      <th>avg_molecular_weight_ignore_hydrogen</th>\n",
       "      <th>num_valence_electrons</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_247</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>409.499</td>\n",
       "      <td>409.045587</td>\n",
       "      <td>398.411</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>352.469</td>\n",
       "      <td>351.991109</td>\n",
       "      <td>344.405</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>514.569</td>\n",
       "      <td>514.948537</td>\n",
       "      <td>501.465</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>376.491</td>\n",
       "      <td>376.103190</td>\n",
       "      <td>360.363</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>569.637</td>\n",
       "      <td>569.844956</td>\n",
       "      <td>559.557</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  num_branches  has_benzothiophene  has_carbazole  has_fluorene  \\\n",
       "0   1             2                   0              0             0   \n",
       "1   2             0                   0              0             0   \n",
       "2   3             1                   0              0             0   \n",
       "3   4             2                   0              0             0   \n",
       "4   5             3                   0              0             0   \n",
       "\n",
       "   num_double_bonds  avg_molecular_weight  exact_molecular_weight  \\\n",
       "0                 0               409.499              409.045587   \n",
       "1                 0               352.469              351.991109   \n",
       "2                 2               514.569              514.948537   \n",
       "3                 4               376.491              376.103190   \n",
       "4                 0               569.637              569.844956   \n",
       "\n",
       "   avg_molecular_weight_ignore_hydrogen  num_valence_electrons    ...     \\\n",
       "0                               398.411                    136    ...      \n",
       "1                               344.405                    110    ...      \n",
       "2                               501.465                    146    ...      \n",
       "3                               360.363                    132    ...      \n",
       "4                               559.557                    154    ...      \n",
       "\n",
       "   feat_247  feat_248  feat_249  feat_250  feat_251  feat_252  feat_253  \\\n",
       "0         0         1         0         0         0         0         0   \n",
       "1         0         1         0         0         0         0         0   \n",
       "2         0         1         0         0         0         0         0   \n",
       "3         0         1         0         0         0         0         0   \n",
       "4         0         1         0         0         0         0         0   \n",
       "\n",
       "   feat_254  feat_255  feat_256  \n",
       "0         0         0         0  \n",
       "1         0         0         0  \n",
       "2         0         0         0  \n",
       "3         0         0         0  \n",
       "4         0         0         0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in old test data and merge with new features\n",
    "df_test_old = pd.read_csv(\"test.csv\")\n",
    "df_test = df_test.merge(df_test_old, on=[\"Id\"])\n",
    "# Fix columns\n",
    "df_test = df_test.drop(['smiles_x'],axis=1)\n",
    "df_test = df_test.rename(columns = {'smiles_y':'smiles'})\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "df_test.to_csv('FINAL_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete old dfs\n",
    "del df_test_old\n",
    "del df_test_parts\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *IF FEATURE ENGINEERING IS DONE: START HERE*\n",
    "# IV. Model Selection \n",
    "1. Read training data, store output values, and remove output values from df_train\n",
    "2. Split training data into training set and validation set\n",
    "3. Model Selection -  Test various models\n",
    "    1. Linear Regression\n",
    "    2. Transform data using PCA\n",
    "    3. Random Forest (extra trees) using PCA\n",
    "    4. ... (TAYLOR AND ANDREW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read training data, store output values, and remove output values from df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('FINAL_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_branches</th>\n",
       "      <th>has_benzothiophene</th>\n",
       "      <th>has_carbazole</th>\n",
       "      <th>has_fluorene</th>\n",
       "      <th>num_double_bonds</th>\n",
       "      <th>avg_molecular_weight</th>\n",
       "      <th>exact_molecular_weight</th>\n",
       "      <th>avg_molecular_weight_ignore_hydrogen</th>\n",
       "      <th>num_valence_electrons</th>\n",
       "      <th>num_radical_electrons</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>470.462</td>\n",
       "      <td>470.907296</td>\n",
       "      <td>461.390</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>352.545</td>\n",
       "      <td>352.085202</td>\n",
       "      <td>336.417</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>399.576</td>\n",
       "      <td>399.032016</td>\n",
       "      <td>386.472</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>379.567</td>\n",
       "      <td>379.084867</td>\n",
       "      <td>362.431</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>396.391</td>\n",
       "      <td>396.042944</td>\n",
       "      <td>388.327</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_branches  has_benzothiophene  has_carbazole  has_fluorene  \\\n",
       "0             3                   0              0             0   \n",
       "1             1                   0              0             0   \n",
       "2             2                   0              0             0   \n",
       "3             1                   0              0             0   \n",
       "4             1                   0              0             0   \n",
       "\n",
       "   num_double_bonds  avg_molecular_weight  exact_molecular_weight  \\\n",
       "0                 0               470.462              470.907296   \n",
       "1                 5               352.545              352.085202   \n",
       "2                 1               399.576              399.032016   \n",
       "3                 4               379.567              379.084867   \n",
       "4                 0               396.391              396.042944   \n",
       "\n",
       "   avg_molecular_weight_ignore_hydrogen  num_valence_electrons  \\\n",
       "0                               461.390                    130   \n",
       "1                               336.417                    118   \n",
       "2                               386.472                    128   \n",
       "3                               362.431                    128   \n",
       "4                               388.327                    136   \n",
       "\n",
       "   num_radical_electrons  ...   feat_248  feat_249  feat_250  feat_251  \\\n",
       "0                      0  ...          1         0         0         0   \n",
       "1                      0  ...          1         0         0         1   \n",
       "2                      0  ...          1         0         0         0   \n",
       "3                      0  ...          1         0         0         0   \n",
       "4                      0  ...          1         0         0         0   \n",
       "\n",
       "   feat_252  feat_253  feat_254  feat_255  feat_256   gap  \n",
       "0         0         0         0         0         0  1.19  \n",
       "1         0         0         0         0         0  1.60  \n",
       "2         1         0         0         0         0  1.49  \n",
       "3         1         0         0         0         0  1.36  \n",
       "4         0         0         0         0         0  1.98  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (999997, 369)\n",
      "Train gap: (999997,)\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'smiles' column \n",
    "df_train = df_train.drop(['smiles'], axis=1)\n",
    "\n",
    "# Store gap values\n",
    "Y_train = df_train.gap.values\n",
    "\n",
    "# Delete 'gap' column\n",
    "df_train = df_train.drop(['gap'], axis=1)\n",
    "X_train = df_train.values\n",
    "print \"Train features:\", X_train.shape\n",
    "print \"Train gap:\", Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split training data into training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Partition Training Data into Training, Validation\n",
    "cross_X_train, cross_X_valid, cross_Y_train, cross_Y_valid = train_test_split(X_train, Y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Selection -  Test various models\n",
    "#### A. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit Linear Regression to cross_X_train and validate it on validations set\n",
    "LR = LinearRegression()\n",
    "LR.fit(cross_X_train, cross_Y_train)\n",
    "LR_pred = LR.predict(cross_X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of coefficients that are zero: 257\n",
      "Total number of coefficients: 369\n",
      "[77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 108, 110, 111, 112, 114, 115, 116, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 236, 237, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 309, 310, 313, 314, 315, 316, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 361, 362, 365, 366, 367, 368]\n"
     ]
    }
   ],
   "source": [
    "LR.coef_\n",
    "zero_coefs = []\n",
    "for i in xrange(len(LR.coef_)):\n",
    "    if LR.coef_[i] == 0:\n",
    "        zero_coefs.append(i)\n",
    "print \"Number of coefficients that are zero:\", len(zero_coefs)\n",
    "print \"Total number of coefficients:\", len(LR.coef_)\n",
    "print zero_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.49813187  2.0241977   1.83322251 ...,  1.84260857  1.77574646\n",
      "  2.06445611]\n"
     ]
    }
   ],
   "source": [
    "print LR_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20278958695606894"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(cross_Y_valid, LR_pred)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Transform data using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=60)\n",
    "cross_X_train_transf = pca.fit_transform(cross_X_train)\n",
    "cross_X_valid_transf = pca.transform(cross_X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Random Forest (extra trees) using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extraTrees_pca = ExtraTreesRegressor(n_estimators=100,n_jobs=2)\n",
    "tree_est_wPCA = extraTrees_pca.fit(cross_X_train_transf, cross_Y_train)\n",
    "pca_exTree_pred = tree_est_wPCA.predict(cross_X_valid_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14639850122558837"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "mean_squared_error(cross_Y_valid, pca_exTree_pred)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D1. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum RMSE is 0.20295979127\n",
      "minimum alpha is 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set parameters to test\n",
    "# alphas = np.logspace(-4, -.5, 30) alpha = 0.0001 was best with RMSE of 0.25\n",
    "alphas = [.5,.1,.01,.001,.0001,.00001]\n",
    "\n",
    "# Initialize minimums \n",
    "\n",
    "minimum_alpha = 100\n",
    "minimum_RMSE = 100\n",
    "for alpha in alphas:\n",
    "    \n",
    "    # Fit model and predict on validation\n",
    "    clf = linear_model.Lasso(alpha=alpha)\n",
    "    clf.fit(cross_X_train,cross_Y_train)\n",
    "    y_pred = clf.predict(cross_X_valid) \n",
    "    \n",
    "    # Calculate RMSE and update minimum RMSE if possible\n",
    "    RMSE = np.sqrt(mean_squared_error(cross_Y_valid, y_pred))\n",
    "    if RMSE < minimum_RMSE:\n",
    "        minimum_RMSE = RMSE\n",
    "        minimum_alpha = alpha\n",
    "    \n",
    "print \"minimum RMSE is\", minimum_RMSE\n",
    "print \"minimum alpha is\",minimum_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D2. Lasso using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum RMSE is 0.20282437003\n",
      "minimum alpha is 1e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set parameters to test\n",
    "# alphas = np.logspace(-4, -.5, 30) alpha = 0.0001 was best with RMSE of 0.25\n",
    "alphas = [.5,.1,.01,.001,.0001,.00001]\n",
    "\n",
    "# Initialize minimums \n",
    "\n",
    "minimum_alpha = 100\n",
    "minimum_RMSE = 100\n",
    "for alpha in alphas:\n",
    "    \n",
    "    # Fit model and predict on validation\n",
    "    clf = linear_model.Lasso(alpha=alpha)\n",
    "    clf.fit(cross_X_train_transf,cross_Y_train)\n",
    "    y_pred = clf.predict(cross_X_valid_transf) \n",
    "    \n",
    "    # Calculate RMSE and update minimum RMSE if possible\n",
    "    RMSE = np.sqrt(mean_squared_error(cross_Y_valid, y_pred))\n",
    "    if RMSE < minimum_RMSE:\n",
    "        minimum_RMSE = RMSE\n",
    "        minimum_alpha = alpha\n",
    "    \n",
    "print \"minimum RMSE is\", minimum_RMSE\n",
    "print \"minimum alpha is\",minimum_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D1. Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set parameters to test\n",
    "alphas = [.5,.1,.01,.001,.0001,.00001] \n",
    "ratios = [.5,.1,.01,.001,.0001,.00001]\n",
    "counter = 0\n",
    "\n",
    "# Initialize minimums\n",
    "minimum_alpha = 100\n",
    "minimum_ratio = 100\n",
    "minimum_RMSE = 100\n",
    "for alpha in alphas:\n",
    "    for ratio in ratios:\n",
    "        \n",
    "        # Fit model and predict on validation\n",
    "        clf = linear_model.ElasticNet(alpha=alpha, l1_ratio=ratio)\n",
    "        clf.fit(cross_X_train,cross_Y_train)\n",
    "        y_pred = clf.predict(cross_X_valid) \n",
    "        \n",
    "        # Calculate RMSE and update minimum RMSE if possible\n",
    "        RMSE = np.sqrt(mean_squared_error(cross_Y_valid, y_pred))\n",
    "        if RMSE < minimum_RMSE:\n",
    "            minimum_RMSE = RMSE\n",
    "            minimum_alpha = alpha\n",
    "            minimum_ratio = ratio\n",
    "    counter +=1\n",
    "    print counter\n",
    "print \"minimum RMSE is\", minimum_RMSE\n",
    "print \"minimum alpha is\",minimum_alpha\n",
    "print \"minimum ratio is\",minimum_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D2. Elastic Net using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum RMSE is 0.202846013573\n",
      "minimum alpha is 1e-05\n",
      "minimum ratio is 0.5\n"
     ]
    }
   ],
   "source": [
    "# Set parameters to test\n",
    "alphas = [.5,.1,.01,.001,.0001,.00001] \n",
    "ratios = [.5,.1,.01,.001,.0001,.00001]\n",
    "\n",
    "# Initialize minimums\n",
    "minimum_alpha = 100\n",
    "minimum_ratio = 100\n",
    "minimum_RMSE = 100\n",
    "for alpha in alphas:\n",
    "    for ratio in ratios:\n",
    "        \n",
    "        # Fit model and predict on validation\n",
    "        clf = linear_model.ElasticNet(alpha=alpha, l1_ratio=ratio)\n",
    "        clf.fit(cross_X_train_transf,cross_Y_train)\n",
    "        y_pred = clf.predict(cross_X_valid_transf) \n",
    "        \n",
    "        # Calculate RMSE and update minimum RMSE if possible\n",
    "        RMSE = np.sqrt(mean_squared_error(cross_Y_valid, y_pred))\n",
    "        if RMSE < minimum_RMSE:\n",
    "            minimum_RMSE = RMSE\n",
    "            minimum_alpha = alpha\n",
    "            minimum_ratio = ratio\n",
    "\n",
    "print \"minimum RMSE is\", minimum_RMSE\n",
    "print \"minimum alpha is\",minimum_alpha\n",
    "print \"minimum ratio is\",minimum_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove cross validation datasets\n",
    "del cross_X_train, cross_X_valid, cross_Y_train, cross_Y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# V. Final Model Construction and Test Set Prediction \n",
    "1. Read in training data\n",
    "2. Read in test data\n",
    "3. If using PCA, transform training and test data\n",
    "4. Train model using training data\n",
    "5. Predict output using test data\n",
    "6. Write output to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('FINAL_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#delete 'Id' column\n",
    "df_test = df_test.drop(['Id'], axis=1)\n",
    "# Drop the 'smiles' column\n",
    "df_test= df_test.drop(['smiles'], axis=1)\n",
    "X_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=60)\n",
    "extraTrees_pca = ExtraTreesRegressor(n_estimators=100,n_jobs=2)\n",
    "# extraTrees = ExtraTreesRegressor(n_estimators=25,n_jobs=2)\n",
    "\n",
    "X_transf = pca.fit_transform(X_train)\n",
    "X_test_transf = pca.transform(X_test)\n",
    "\n",
    "tree_est_wPCA = extraTrees_pca.fit(X_transf, Y_train)\n",
    "# tree_estimator = extraTrees.fit(X_train, Y_train)\n",
    "\n",
    "pca_exTree_pred = tree_est_wPCA.predict(X_test_transf)\n",
    "# exTree_pred = tree_estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write to file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
