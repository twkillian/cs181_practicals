{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook outlines the final model tuning and set of predictions that ML Marauders have made for CS 181 Practical 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.linear_model import Ridge, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and gently process the data (much of the preprocessing was done in FINAL.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_branches</th>\n",
       "      <th>has_benzothiophene</th>\n",
       "      <th>has_carbazole</th>\n",
       "      <th>has_fluorene</th>\n",
       "      <th>num_double_bonds</th>\n",
       "      <th>avg_molecular_weight</th>\n",
       "      <th>exact_molecular_weight</th>\n",
       "      <th>avg_molecular_weight_ignore_hydrogen</th>\n",
       "      <th>num_valence_electrons</th>\n",
       "      <th>num_radical_electrons</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>470.462</td>\n",
       "      <td>470.907296</td>\n",
       "      <td>461.390</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>352.545</td>\n",
       "      <td>352.085202</td>\n",
       "      <td>336.417</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>399.576</td>\n",
       "      <td>399.032016</td>\n",
       "      <td>386.472</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>379.567</td>\n",
       "      <td>379.084867</td>\n",
       "      <td>362.431</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>396.391</td>\n",
       "      <td>396.042944</td>\n",
       "      <td>388.327</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_branches  has_benzothiophene  has_carbazole  has_fluorene  \\\n",
       "0             3                   0              0             0   \n",
       "1             1                   0              0             0   \n",
       "2             2                   0              0             0   \n",
       "3             1                   0              0             0   \n",
       "4             1                   0              0             0   \n",
       "\n",
       "   num_double_bonds  avg_molecular_weight  exact_molecular_weight  \\\n",
       "0                 0               470.462              470.907296   \n",
       "1                 5               352.545              352.085202   \n",
       "2                 1               399.576              399.032016   \n",
       "3                 4               379.567              379.084867   \n",
       "4                 0               396.391              396.042944   \n",
       "\n",
       "   avg_molecular_weight_ignore_hydrogen  num_valence_electrons  \\\n",
       "0                               461.390                    130   \n",
       "1                               336.417                    118   \n",
       "2                               386.472                    128   \n",
       "3                               362.431                    128   \n",
       "4                               388.327                    136   \n",
       "\n",
       "   num_radical_electrons  ...   feat_248  feat_249  feat_250  feat_251  \\\n",
       "0                      0  ...          1         0         0         0   \n",
       "1                      0  ...          1         0         0         1   \n",
       "2                      0  ...          1         0         0         0   \n",
       "3                      0  ...          1         0         0         0   \n",
       "4                      0  ...          1         0         0         0   \n",
       "\n",
       "   feat_252  feat_253  feat_254  feat_255  feat_256   gap  \n",
       "0         0         0         0         0         0  1.19  \n",
       "1         0         0         0         0         0  1.60  \n",
       "2         1         0         0         0         0  1.49  \n",
       "3         1         0         0         0         0  1.36  \n",
       "4         0         0         0         0         0  1.98  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train = pd.read_csv('sam_data/rdk_feat_eng_whole_df_train_orig_features.csv')\n",
    "# df_test = pd.read_csv('sam_data/rdk_feat_eng_whole_df_test_orig_features.csv')\n",
    "df_train = pd.read_csv('final_data/FINAL_train.csv')\n",
    "df_test = pd.read_csv('final_data/FINAL_test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>num_branches</th>\n",
       "      <th>has_benzothiophene</th>\n",
       "      <th>has_carbazole</th>\n",
       "      <th>has_fluorene</th>\n",
       "      <th>num_double_bonds</th>\n",
       "      <th>avg_molecular_weight</th>\n",
       "      <th>exact_molecular_weight</th>\n",
       "      <th>avg_molecular_weight_ignore_hydrogen</th>\n",
       "      <th>num_valence_electrons</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_247</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>409.499</td>\n",
       "      <td>409.045587</td>\n",
       "      <td>398.411</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>352.469</td>\n",
       "      <td>351.991109</td>\n",
       "      <td>344.405</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>514.569</td>\n",
       "      <td>514.948537</td>\n",
       "      <td>501.465</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>376.491</td>\n",
       "      <td>376.103190</td>\n",
       "      <td>360.363</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>569.637</td>\n",
       "      <td>569.844956</td>\n",
       "      <td>559.557</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  num_branches  has_benzothiophene  has_carbazole  has_fluorene  \\\n",
       "0   1             2                   0              0             0   \n",
       "1   2             0                   0              0             0   \n",
       "2   3             1                   0              0             0   \n",
       "3   4             2                   0              0             0   \n",
       "4   5             3                   0              0             0   \n",
       "\n",
       "   num_double_bonds  avg_molecular_weight  exact_molecular_weight  \\\n",
       "0                 0               409.499              409.045587   \n",
       "1                 0               352.469              351.991109   \n",
       "2                 2               514.569              514.948537   \n",
       "3                 4               376.491              376.103190   \n",
       "4                 0               569.637              569.844956   \n",
       "\n",
       "   avg_molecular_weight_ignore_hydrogen  num_valence_electrons    ...     \\\n",
       "0                               398.411                    136    ...      \n",
       "1                               344.405                    110    ...      \n",
       "2                               501.465                    146    ...      \n",
       "3                               360.363                    132    ...      \n",
       "4                               559.557                    154    ...      \n",
       "\n",
       "   feat_247  feat_248  feat_249  feat_250  feat_251  feat_252  feat_253  \\\n",
       "0         0         1         0         0         0         0         0   \n",
       "1         0         1         0         0         0         0         0   \n",
       "2         0         1         0         0         0         0         0   \n",
       "3         0         1         0         0         0         0         0   \n",
       "4         0         1         0         0         0         0         0   \n",
       "\n",
       "   feat_254  feat_255  feat_256  \n",
       "0         0         0         0  \n",
       "1         0         0         0  \n",
       "2         0         0         0  \n",
       "3         0         0         0  \n",
       "4         0         0         0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using StandardScaler to normalize non-binary columns\n",
    "scaler = StandardScaler()\n",
    "binary_cols = ['feat_%03d' % ii for ii in range(1,257)]\n",
    "binary_cols.append('has_benzothiophene')\n",
    "binary_cols.append('has_carbazole')\n",
    "binary_cols.append('has_fluorene')\n",
    "binary_cols.append('smiles')\n",
    "binary_cols.append('Id')\n",
    "non_binary_cols = np.array([col for col in df_test.columns if col not in binary_cols]).flatten()\n",
    "\n",
    "df_train[non_binary_cols] = scaler.fit_transform(df_train[non_binary_cols])\n",
    "df_test[non_binary_cols] = scaler.transform(df_test[non_binary_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (999997, 369) Train gap: (999997,)\n",
      "Test features: (824230, 369)\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'smiles' and 'Id' columns\n",
    "df_train = df_train.drop(['smiles'], axis=1)\n",
    "df_test = df_test.drop(['Id'], axis=1)\n",
    "df_test = df_test.drop(['smiles'], axis=1)\n",
    "\n",
    "# Store gap values\n",
    "Y_train = df_train.gap.values\n",
    "\n",
    "# Delete 'gap' column\n",
    "df_train = df_train.drop(['gap'], axis=1)\n",
    "X_train = df_train.values\n",
    "X_test = df_test.values\n",
    "print \"Train features:\", X_train.shape, \"Train gap:\", Y_train.shape\n",
    "print \"Test features:\", X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split training data into training and validation sets as well as begin some k-fold CV\n",
    "cross_X_train, cross_X_valid, cross_Y_train, cross_Y_valid = train_test_split(X_train, Y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For classification purposes, round target values to nearest .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Round to nearest integer\n",
    "Y_clf_train, Y_clf_valid = np.round(cross_Y_train), np.round(cross_Y_valid)\n",
    "Y_full_clf_train = np.round(Y_train)\n",
    "# Round to nearest .5\n",
    "# Y_clf_train, Y_clf_valid = (((np.round(2*cross_Y_train)/2.0)-0.5)/0.5).astype(int), (((np.round(2*cross_Y_valid)/2.0)-0.5)/0.5).astype(int)\n",
    "# Y_full_clf_train = (((np.round(2*Y_train)/2.0)-.5)/.5).astype(int)\n",
    "# Round to nearest .25\n",
    "# Y_clf_train, Y_clf_valid = (((np.round(4*cross_Y_train)/4.0)-.25)/.25).astype(int), (((np.round(4*cross_Y_valid)/4.0)-.25)/.25).astype(int)\n",
    "# Y_full_clf_train = (((np.round(4*Y_train)/4.0)-.25)/.25).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Training' features:  (699997, 369)\n",
      "'Validate' features:  (300000, 369)\n"
     ]
    }
   ],
   "source": [
    "print \"'Training' features: \", cross_X_train.shape\n",
    "print \"'Validate' features: \", cross_X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOAL:\n",
    "\n",
    "This notebook is set-up to chain together classification and regression methods. The thought is that we can, after we've trained the two models, to first apply a classifier to the data (in a clustering kind of sense) and then use the category or neighborhood that the sample is assigned as an additional feature to perform regression. Here the category or label will be the closest integer to the gap value. The idea behind this is to hijack the regression into a local region of the expected HOMO-LUMO gap based on the label. The hope is that this will pin the regressor closer to the right value. \n",
    "\n",
    "It's imperative that we get as accurate of a classifier as we can.\n",
    "\n",
    "Fingers crossed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First: Let's build a classifier that will adequately label the samples\n",
    "\n",
    "We'll start with Logistic Regression and try to fit the best model using a collection of C values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 0.660916666667\n",
      "0.01 0.669706666667\n",
      "0.1 0.67299\n",
      "1.0 0.67306\n",
      "10.0 0.673676666667\n",
      "CPU times: user 39min 47s, sys: 38.2 s, total: 40min 25s\n",
      "Wall time: 23min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logReg_training_acc = 0\n",
    "logReg_test_acc = 0\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "for c in Cs:\n",
    "    clf_logReg=LogisticRegression(penalty=\"l2\",C=c, solver='lbfgs')\n",
    "    clf_logReg.fit(cross_X_train,Y_clf_train)\n",
    "    training_acc = clf_logReg.score(cross_X_train,Y_clf_train)\n",
    "    test_acc = clf_logReg.score(cross_X_valid,Y_clf_valid)\n",
    "    print c, test_acc\n",
    "    if logReg_test_acc < test_acc:\n",
    "        logReg_test_acc = test_acc\n",
    "        logReg_training_acc = training_acc\n",
    "        best_logReg = clf_logReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.673\n",
      "Test Accuracy: 0.674\n"
     ]
    }
   ],
   "source": [
    "logReg_training_acc = best_logReg.score(cross_X_train,Y_clf_train)\n",
    "logReg_test_acc = best_logReg.score(cross_X_valid,Y_clf_valid)\n",
    "print \"Training Accuracy: %0.3f\" % logReg_training_acc\n",
    "print \"Test Accuracy: %0.3f\" % logReg_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate predicted labels onto test/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_clf_pred = best_logReg.predict(cross_X_valid)\n",
    "X_train_clf = np.vstack((cross_X_train.T,Y_clf_train)).T\n",
    "X_valid_clf = np.vstack((cross_X_valid.T,Y_clf_valid)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now onto ExtraTrees, fronted with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 100\n",
      "0.100909833779\n",
      "40 200\n",
      "0.100748042017\n",
      "45 100\n",
      "0.100666057888\n",
      "45 200\n",
      "0.100531872291\n",
      "PCA with 45 components chained ExtraTrees with 200 estimators had RMSE of 0.100531872291\n",
      "CPU times: user 5h 28min 18s, sys: 4min 11s, total: 5h 32min 30s\n",
      "Wall time: 1h 30min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pcaExtraTrees_RMSE = 100\n",
    "\n",
    "pca_components = [40, 45, 60]\n",
    "num_estimators = [100, 200]\n",
    "\n",
    "for comps in pca_components:\n",
    "    pca = PCA(n_components=comps)\n",
    "    X_train_tr = pca.fit_transform(X_train_clf)\n",
    "    X_valid_tr = pca.transform(X_valid_clf)\n",
    "    \n",
    "    for n_estimators in num_estimators:\n",
    "        \n",
    "        extratrees_clf = ExtraTreesRegressor(n_estimators=n_estimators,n_jobs=-1)\n",
    "        extratrees_clf.fit(X_train_tr,cross_Y_train)\n",
    "        y_pred = extratrees_clf.predict(X_valid_tr)\n",
    "        \n",
    "        RMSE = np.sqrt(mean_squared_error(cross_Y_valid,y_pred))\n",
    "        if RMSE < pcaExtraTrees_RMSE:\n",
    "            print comps, n_estimators\n",
    "            print RMSE\n",
    "            pcaExtraTrees_RMSE = RMSE\n",
    "            pcaExtraTrees_estimators = n_estimators\n",
    "            pcaExtraTrees_components = comps\n",
    "            best_pcaExtraTrees = extratrees_clf\n",
    "            \n",
    "print \"PCA with {0} components chained ExtraTrees with {1} estimators had RMSE of {2}\".format(pcaExtraTrees_components,pcaExtraTrees_estimators,pcaExtraTrees_RMSE)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We're also going to tune a Ridge Regression to have double coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RMSE: 0.117605336561 with alpha: 0.0117210229753\n",
      "CPU times: user 4min 25s, sys: 29.6 s, total: 4min 55s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridge_RMSE = 100\n",
    "alphas = np.logspace(-4, 1, 30)\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge_clf = Ridge(alpha=alpha)\n",
    "    ridge_clf.fit(X_train_clf, cross_Y_train)\n",
    "    y_pred = ridge_clf.predict(X_valid_clf)\n",
    "    \n",
    "    RMSE = np.sqrt(mean_squared_error(cross_Y_valid,y_pred))\n",
    "    if RMSE < ridge_RMSE:\n",
    "        ridge_RMSE = RMSE\n",
    "        ridge_alpha = alpha\n",
    "        best_ridge = ridge_clf\n",
    "        \n",
    "print \"Ridge RMSE: {0} with alpha: {1}\".format(ridge_RMSE,ridge_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('final_classifier_and_regressors.pkl','w') as f:\n",
    "    pickle.dump((best_logReg,best_pcaExtraTrees,pcaExtraTrees_components,best_ridge),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('final_classifier_and_regressors.pkl','r') as fopen:\n",
    "#     best_logReg, best_pcaExtraTrees, pcaExtraTrees_components, best_ridge = pickle.load(fopen)\n",
    "    \n",
    "# After opening this, you may need to re-configure the test and training set, that is if you have to restart the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on full training set, run on full test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will train the classifier and the regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Classification of test set\n",
      "CPU times: user 13min 43s, sys: 23.3 s, total: 14min 7s\n",
      "Wall time: 8min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train classifier\n",
    "# best_logReg.fit(X_train,Y_full_clf_train)\n",
    "\n",
    "# Run classifier on test set\n",
    "label_pred = best_logReg.predict(X_test)\n",
    "\n",
    "# Concatenate full training labels to full test set\n",
    "X_full_train_clf = np.vstack((X_train.T,Y_full_clf_train)).T\n",
    "# Concatenate predicted labels onto test set as a new feature\n",
    "X_test_clf = np.vstack((X_test.T,label_pred)).T\n",
    "\n",
    "print \"Completed Classification of test set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed ExtraTrees Regression\n",
      "CPU times: user 1h 53min 31s, sys: 1min 37s, total: 1h 55min 8s\n",
      "Wall time: 32min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train ExtraTrees Regressor\n",
    "pca = PCA(n_components=pcaExtraTrees_components)\n",
    "X_full_train_tr = pca.fit_transform(X_full_train_clf)\n",
    "best_pcaExtraTrees.fit(X_full_train_tr,Y_train)\n",
    "\n",
    "# Run ExtraTrees Regressor\n",
    "X_test_clf_tr = pca.transform(X_test_clf)\n",
    "pcaExtraTrees_pred = best_pcaExtraTrees.predict(X_test_clf_tr)\n",
    "\n",
    "# Save the ExtraTrees Predictions\n",
    "write_to_file(\"pca_extraTrees_FINAL_TWK_10Feb.csv\",pcaExtraTrees_pred)\n",
    "\n",
    "print \"Completed ExtraTrees Regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train Ridge Regression\n",
    "best_ridge.fit(X_full_train_clf,Y_train)\n",
    "\n",
    "# Run Ridge Regressor\n",
    "ridge_pred = best_ridge.predict(X_test_clf)\n",
    "\n",
    "# Save the Ridge Predictions\n",
    "write_to_file(\"ridge_FINAL_TWK_10Feb.csv\",ridge_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
